{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2653111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb5c3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_excel('Participants_Data_News_category/Data_Train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "208bff93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "      <th>SECTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7326</th>\n",
       "      <td>For its 2019 manifesto, BJP has simply copy pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>The court’s preliminary injunction barred Appl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>These features will be broadly available in th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4818</th>\n",
       "      <td>The single interface where users can swipe pos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>NEW DELHI: The initial public offering of Neog...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  STORY  SECTION\n",
       "7326  For its 2019 manifesto, BJP has simply copy pa...        0\n",
       "434   The court’s preliminary injunction barred Appl...        1\n",
       "6290  These features will be broadly available in th...        1\n",
       "4818  The single interface where users can swipe pos...        1\n",
       "845   NEW DELHI: The initial public offering of Neog...        3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21567e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SECTION'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "435598fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7628 entries, 0 to 7627\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   STORY    7628 non-null   object\n",
      " 1   SECTION  7628 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 119.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d0b227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2772\n",
       "2    1924\n",
       "0    1686\n",
       "3    1246\n",
       "Name: SECTION, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SECTION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa7af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fea719e0",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fca588a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae51f86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7628\n",
      "1    2772\n",
      "2    1924\n",
      "0    1686\n",
      "3    1246\n",
      "Name: SECTION, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['SECTION'].count())#total value\n",
    "\n",
    "print(df['SECTION'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6c980d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    36.339801\n",
      "2    25.222863\n",
      "0    22.102779\n",
      "3    16.334557\n",
      "Name: SECTION, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='SECTION', ylabel='Percent'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjYAAAGwCAYAAAC6ty9tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnsklEQVR4nO3df3SU5Z338c9IyBDIEEUgkynhVw0KBHCLGomWBJfwQ4sinq0VZLGPtlDEJQ0YilRJrSbA2QV0OYi2CtmuiOsxspyt9RAxBDFEEWRFfii2WYjAkEVDfkiYRHI9f/gwD0MSTYYJM7l4v865z2Gu+7rv+X5JuPjknjszDmOMEQAAgAWuCHcBAAAAoUKwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwRlS4C2hvjY2NOnbsmFwulxwOR7jLAQAArWCMUU1NjTwej664ovXXYawPNseOHVNiYmK4ywAAAEEoLy9Xnz59Wj3f+mDjcrkkffsX07179zBXAwAAWqO6ulqJiYn+/8dby/pgc+7lp+7duxNsAADoYNp6Gwk3DwMAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGmENNjk5OXI4HAGb2+327zfGKCcnRx6PRzExMUpPT9e+ffvCWDEAAIhkYb9iM3ToUB0/fty/7d27179v2bJlWr58uVatWqWdO3fK7XYrIyNDNTU1YawYAABEqrAHm6ioKLndbv/Wq1cvSd9erVm5cqUWLVqkKVOmKDk5Wfn5+Tp9+rTWr18f5qoBAEAkigp3AYcOHZLH45HT6VRKSopyc3M1cOBAlZWVyev1aty4cf65TqdTaWlpKikp0cyZM5s9n8/nk8/n8z+urq5u1/qPHDmikydPtutz4PLTs2dP9e3bN9xlAECHE9Zgk5KSon/7t3/ToEGDdOLECT311FNKTU3Vvn375PV6JUnx8fEBx8THx+vw4cMtnjMvL0+/+93v2rXuc44cOaLrrhusurrTl+T5cPmIiemqgwcPEG4AoI3CGmwmTpzo//OwYcM0atQo/fCHP1R+fr5uvvlmSZLD4Qg4xhjTZOx8CxcuVFZWlv9xdXW1EhMTQ1z5t06ePKm6utNK+T+L1T2hf7s8By4/1cf/R++/9DudPHmSYAMAbRT2l6LO161bNw0bNkyHDh3S5MmTJUler1cJCQn+ORUVFU2u4pzP6XTK6XS2d6kBuif0V4++117S5wQAAE2F/ebh8/l8Ph04cEAJCQkaMGCA3G63CgsL/fvr6+tVXFys1NTUMFYJAAAiVViv2MyfP1+TJk1S3759VVFRoaeeekrV1dWaMWOGHA6HMjMzlZubq6SkJCUlJSk3N1ddu3bV1KlTw1k2AACIUGENNl988YXuu+8+nTx5Ur169dLNN9+s0tJS9evXT5KUnZ2turo6zZ49W5WVlUpJSdHmzZvlcrnCWTYAAIhQYQ02GzZs+M79DodDOTk5ysnJuTQFAQCADi2i7rEBAAC4GAQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFgjYoJNXl6eHA6HMjMz/WPGGOXk5Mjj8SgmJkbp6enat29f+IoEAAARLSKCzc6dO/XCCy9o+PDhAePLli3T8uXLtWrVKu3cuVNut1sZGRmqqakJU6UAACCShT3Y1NbWatq0afrDH/6gq666yj9ujNHKlSu1aNEiTZkyRcnJycrPz9fp06e1fv36Fs/n8/lUXV0dsAEAgMtD2IPNww8/rDvuuENjx44NGC8rK5PX69W4ceP8Y06nU2lpaSopKWnxfHl5eYqLi/NviYmJ7VY7AACILGENNhs2bNDu3buVl5fXZJ/X65UkxcfHB4zHx8f79zVn4cKFqqqq8m/l5eWhLRoAAESsqHA9cXl5uebOnavNmzerS5cuLc5zOBwBj40xTcbO53Q65XQ6Q1YnAADoOMJ2xWbXrl2qqKjQyJEjFRUVpaioKBUXF+vZZ59VVFSU/0rNhVdnKioqmlzFAQAAkMIYbP7+7/9ee/fu1Z49e/zbDTfcoGnTpmnPnj0aOHCg3G63CgsL/cfU19eruLhYqamp4SobAABEsLC9FOVyuZScnBww1q1bN1199dX+8czMTOXm5iopKUlJSUnKzc1V165dNXXq1HCUDAAAIlzYgk1rZGdnq66uTrNnz1ZlZaVSUlK0efNmuVyucJcGAAAiUEQFm61btwY8djgcysnJUU5OTljqAQAAHUvY38cGAAAgVAg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGCNsAab5557TsOHD1f37t3VvXt3jRo1Sn/5y1/8+40xysnJkcfjUUxMjNLT07Vv374wVgwAACJZWINNnz59tGTJEn344Yf68MMPddttt+muu+7yh5dly5Zp+fLlWrVqlXbu3Cm3262MjAzV1NSEs2wAABChwhpsJk2apNtvv12DBg3SoEGD9PTTTys2NlalpaUyxmjlypVatGiRpkyZouTkZOXn5+v06dNav359OMsGAAARKmLusTl79qw2bNigr7/+WqNGjVJZWZm8Xq/GjRvnn+N0OpWWlqaSkpIWz+Pz+VRdXR2wAQCAy0PYg83evXsVGxsrp9OpWbNm6Y033tCQIUPk9XolSfHx8QHz4+Pj/fuak5eXp7i4OP+WmJjYrvUDAIDIEfZgc+2112rPnj0qLS3Vr371K82YMUP79+/373c4HAHzjTFNxs63cOFCVVVV+bfy8vJ2qx0AAESWqHAXEB0drWuuuUaSdMMNN2jnzp165plntGDBAkmS1+tVQkKCf35FRUWTqzjnczqdcjqd7Vs0AACISGG/YnMhY4x8Pp8GDBggt9utwsJC/776+noVFxcrNTU1jBUCAIBIFdQVm06dOun48ePq3bt3wPiXX36p3r176+zZs606z2OPPaaJEycqMTFRNTU12rBhg7Zu3aq33npLDodDmZmZys3NVVJSkpKSkpSbm6uuXbtq6tSpwZQNAAAsF1SwMcY0O+7z+RQdHd3q85w4cULTp0/X8ePHFRcXp+HDh+utt95SRkaGJCk7O1t1dXWaPXu2KisrlZKSos2bN8vlcgVTNgAAsFybgs2zzz4r6dsbev/4xz8qNjbWv+/s2bPatm2brrvuulaf78UXX/zO/Q6HQzk5OcrJyWlLmQAA4DLVpmCzYsUKSd9esVmzZo06derk3xcdHa3+/ftrzZo1oa0QAACgldoUbMrKyiRJY8aMUUFBga666qp2KQoAACAYQd1jU1RUFOo6AAAALlpQwebs2bNat26dtmzZooqKCjU2Ngbsf+edd0JSHAAAQFsEFWzmzp2rdevW6Y477lBycvJ3vhMwAADApRJUsNmwYYP+4z/+Q7fffnuo6wEAAAhaUO88fP7HIAAAAESKoILNvHnz9Mwzz7T4Rn0AAADhENRLUdu3b1dRUZH+8pe/aOjQoercuXPA/oKCgpAUBwAA0BZBBZsrr7xSd999d6hrAQAAuChBBZu1a9eGug4AAICLFtQ9NpL0zTff6O2339bzzz+vmpoaSdKxY8dUW1sbsuIAAADaIqgrNocPH9aECRN05MgR+Xw+ZWRkyOVyadmyZTpz5gyfFwUAAMIiqCs2c+fO1Q033KDKykrFxMT4x++++25t2bIlZMUBAAC0RdC/FfXee+8pOjo6YLxfv346evRoSAoDAABoq6Cu2DQ2Nurs2bNNxr/44gu5XK6LLgoAACAYQQWbjIwMrVy50v/Y4XCotrZWixcv5mMWAABA2AT1UtSKFSs0ZswYDRkyRGfOnNHUqVN16NAh9ezZU6+88kqoawQAAGiVoIKNx+PRnj17tGHDBu3atUuNjY168MEHNW3atICbiQEAAC6loIKNJMXExOjnP/+5fv7zn4eyHgAAgKAFdY9NXl6eXnrppSbjL730kpYuXXrRRQEAAAQjqGDz/PPP67rrrmsyPnToUN6cDwAAhE1Qwcbr9SohIaHJeK9evXT8+PGLLgoAACAYQQWbxMREvffee03G33vvPXk8nosuCgAAIBhB3Tz80EMPKTMzUw0NDbrtttskSVu2bFF2drbmzZsX0gIBAABaK6hgk52dra+++kqzZ89WfX29JKlLly5asGCBFi5cGNICAQAAWqvNwebs2bPavn27FixYoMcff1wHDhxQTEyMkpKS5HQ626NGAACAVmlzsOnUqZPGjx+vAwcOaMCAAbrxxhvboy7gsnfgwIFwlwDL+Hw+fgBFyPXs2VN9+/YNdxl+Qb0UNWzYMP3tb3/TgAEDQl0PcNmrq/pSkkP3339/uEuBbRwOyZhwVwHLxMR01cGDByIm3AQVbJ5++mnNnz9fv//97zVy5Eh169YtYH/37t1DUhxwOWo4XSPJ6PqpC9RrQNP3iwKCcXzvDn2y6QW+rxBS1cf/R++/9DudPHmyYwebCRMmSJLuvPNOORwO/7gxRg6HQ2fPng1NdcBlLLZ3X/Xoe224y4Alqo//jyS+r2C/oIJNUVFRqOsAAAC4aEEFm7S0tFDXAQAAcNGCeudhSXr33Xd1//33KzU1VUePHpUk/elPf9L27dtDVhwAAEBbBBVsXn/9dY0fP14xMTHavXu3fD6fJKmmpka5ubkhLRAAAKC1ggo2Tz31lNasWaM//OEP6ty5s388NTVVu3fvDllxAAAAbRFUsPn00081evToJuPdu3fXqVOnLrYmAACAoAQVbBISEvT55583Gd++fbsGDhx40UUBAAAEI6hgM3PmTM2dO1fvv/++HA6Hjh07ppdfflnz58/X7NmzQ10jAABAqwT96d7V1dUaM2aMzpw5o9GjR8vpdGr+/PmaM2dOqGsEAABolTYFm9OnT+vRRx/Vxo0b1dDQoEmTJmnevHmSpCFDhig2NrZdigQAAGiNNgWbxYsXa926dZo2bZpiYmK0fv16NTY26rXXXmuv+gAAAFqtTcGmoKBAL774on72s59JkqZNm6ZbbrlFZ8+eVadOndqlQAAAgNZq083D5eXl+vGPf+x/fNNNNykqKkrHjh0LeWEAAABt1aZgc/bsWUVHRweMRUVF6ZtvvglpUQAAAMFo00tRxhg98MADcjqd/rEzZ85o1qxZ6tatm3+soKAgdBUCAAC0UpuCzYwZM5qM3X///SErBgAA4GK0KdisXbu2veoAAAC4aEG98zAAAEAkItgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDXCGmzy8vJ04403yuVyqXfv3po8ebI+/fTTgDnGGOXk5Mjj8SgmJkbp6enat29fmCoGAACRLKzBpri4WA8//LBKS0tVWFiob775RuPGjdPXX3/tn7Ns2TItX75cq1at0s6dO+V2u5WRkaGampowVg4AACJRmz7dO9TeeuutgMdr165V7969tWvXLo0ePVrGGK1cuVKLFi3SlClTJEn5+fmKj4/X+vXrNXPmzHCUDQAAIlRE3WNTVVUlSerRo4ckqaysTF6vV+PGjfPPcTqdSktLU0lJSbPn8Pl8qq6uDtgAAMDlIWKCjTFGWVlZuvXWW5WcnCxJ8nq9kqT4+PiAufHx8f59F8rLy1NcXJx/S0xMbN/CAQBAxIiYYDNnzhx9/PHHeuWVV5rsczgcAY+NMU3Gzlm4cKGqqqr8W3l5ebvUCwAAIk9Y77E555FHHtGmTZu0bds29enTxz/udrslfXvlJiEhwT9eUVHR5CrOOU6nU06ns30LBgAAESmsV2yMMZozZ44KCgr0zjvvaMCAAQH7BwwYILfbrcLCQv9YfX29iouLlZqaeqnLBQAAES6sV2wefvhhrV+/Xv/5n/8pl8vlv28mLi5OMTExcjgcyszMVG5urpKSkpSUlKTc3Fx17dpVU6dODWfpAAAgAoU12Dz33HOSpPT09IDxtWvX6oEHHpAkZWdnq66uTrNnz1ZlZaVSUlK0efNmuVyuS1wtAACIdGENNsaY753jcDiUk5OjnJyc9i8IAAB0aBHzW1EAAAAXi2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGuENdhs27ZNkyZNksfjkcPh0MaNGwP2G2OUk5Mjj8ejmJgYpaena9++feEpFgAARLywBpuvv/5aI0aM0KpVq5rdv2zZMi1fvlyrVq3Szp075Xa7lZGRoZqamktcKQAA6AiiwvnkEydO1MSJE5vdZ4zRypUrtWjRIk2ZMkWSlJ+fr/j4eK1fv14zZ85s9jifzyefz+d/XF1dHfrCAQBARIrYe2zKysrk9Xo1btw4/5jT6VRaWppKSkpaPC4vL09xcXH+LTEx8VKUCwAAIkDEBhuv1ytJio+PDxiPj4/372vOwoULVVVV5d/Ky8vbtU4AABA5wvpSVGs4HI6Ax8aYJmPnczqdcjqd7V0WAACIQBF7xcbtdktSk6szFRUVTa7iAAAASBEcbAYMGCC3263CwkL/WH19vYqLi5WamhrGygAAQKQK60tRtbW1+vzzz/2Py8rKtGfPHvXo0UN9+/ZVZmamcnNzlZSUpKSkJOXm5qpr166aOnVqGKsGAACRKqzB5sMPP9SYMWP8j7OysiRJM2bM0Lp165Sdna26ujrNnj1blZWVSklJ0ebNm+VyucJVMgAAiGBhDTbp6ekyxrS43+FwKCcnRzk5OZeuKAAA0GFF7D02AAAAbUWwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrdIhgs3r1ag0YMEBdunTRyJEj9e6774a7JAAAEIEiPti8+uqryszM1KJFi/TRRx/pxz/+sSZOnKgjR46EuzQAABBhIj7YLF++XA8++KAeeughDR48WCtXrlRiYqKee+65cJcGAAAiTFS4C/gu9fX12rVrl37zm98EjI8bN04lJSXNHuPz+eTz+fyPq6qqJEnV1dUhr6+2tlaS9NXhT/WNry7k58flqfr4YUlS1dFD6hzlCHM1sAXfV2gP1d5vXz2pra0N+f+z585njGnbgSaCHT161Egy7733XsD4008/bQYNGtTsMYsXLzaS2NjY2NjY2CzYysvL25QdIvqKzTkOR+BPF8aYJmPnLFy4UFlZWf7HjY2N+uqrr3T11Ve3eEx1dbUSExNVXl6u7t27h67wCESvdqJXO11OvUqXV7/0+v2MMaqpqZHH42nT80V0sOnZs6c6deokr9cbMF5RUaH4+Phmj3E6nXI6nQFjV155Zauer3v37tZ/g51Dr3aiVztdTr1Kl1e/9Prd4uLi2vw8EX3zcHR0tEaOHKnCwsKA8cLCQqWmpoapKgAAEKki+oqNJGVlZWn69Om64YYbNGrUKL3wwgs6cuSIZs2aFe7SAABAhIn4YHPvvffqyy+/1JNPPqnjx48rOTlZb775pvr16xey53A6nVq8eHGTl7BsRK92olc7XU69SpdXv/TafhzGtPX3qAAAACJTRN9jAwAA0BYEGwAAYA2CDQAAsAbBBgAAWMOaYLNt2zZNmjRJHo9HDodDGzdu9O9raGjQggULNGzYMHXr1k0ej0f/+I//qGPHjgWcw+fz6ZFHHlHPnj3VrVs33Xnnnfriiy8C5lRWVmr69OmKi4tTXFycpk+frlOnTl2CDv+/7+r1QjNnzpTD4dDKlSsDxm3q9cCBA7rzzjsVFxcnl8ulm2++OeDT323ptba2VnPmzFGfPn0UExOjwYMHN/kw2I7Sa15enm688Ua5XC717t1bkydP1qeffhowxxijnJwceTwexcTEKD09Xfv27QuY0xH6/b5ebVqfWvN1PV9HXp9a26sN61Nreo2o9SmYz3CKRG+++aZZtGiRef31140k88Ybb/j3nTp1yowdO9a8+uqr5uDBg2bHjh0mJSXFjBw5MuAcs2bNMj/4wQ9MYWGh2b17txkzZowZMWKE+eabb/xzJkyYYJKTk01JSYkpKSkxycnJ5ic/+cmlatMY8929nu+NN94wI0aMMB6Px6xYsSJgny29fv7556ZHjx7m0UcfNbt37zZ//etfzX/913+ZEydO+OfY0utDDz1kfvjDH5qioiJTVlZmnn/+edOpUyezceNG/5yO0uv48ePN2rVrzSeffGL27Nlj7rjjDtO3b19TW1vrn7NkyRLjcrnM66+/bvbu3Wvuvfdek5CQYKqrqztUv9/Xq03rU2u+rud09PWpNb3asj61ptdIWp+sCTbn+67/7M/54IMPjCRz+PBhY8y3i0vnzp3Nhg0b/HOOHj1qrrjiCvPWW28ZY4zZv3+/kWRKS0v9c3bs2GEkmYMHD4a+kVZoqdcvvvjC/OAHPzCffPKJ6devX8DCYVOv9957r7n//vtbPMamXocOHWqefPLJgLEf/ehH5re//a0xpuP2aowxFRUVRpIpLi42xhjT2Nho3G63WbJkiX/OmTNnTFxcnFmzZo0xpuP2e2GvzbFlfWqpVxvXp+Z6tXV9aq7XSFqfrHkpqq2qqqrkcDj8nyO1a9cuNTQ0aNy4cf45Ho9HycnJKikpkSTt2LFDcXFxSklJ8c+5+eabFRcX558TCRobGzV9+nQ9+uijGjp0aJP9tvTa2NioP//5zxo0aJDGjx+v3r17KyUlJeAlHFt6laRbb71VmzZt0tGjR2WMUVFRkT777DONHz9eUsfutaqqSpLUo0cPSVJZWZm8Xm9AL06nU2lpaf46O2q/F/ba0hwb1qfmerV1fbqwV5vXp+a+rpG0Pl2WwebMmTP6zW9+o6lTp/o/kMvr9So6OlpXXXVVwNz4+Hj/h3B6vV717t27yfl69+7d5IM6w2np0qWKiorSP/3TPzW735ZeKyoqVFtbqyVLlmjChAnavHmz7r77bk2ZMkXFxcWS7OlVkp599lkNGTJEffr0UXR0tCZMmKDVq1fr1ltvldRxezXGKCsrS7feequSk5MlyV/LhR92e2EvHa3f5nq9kC3rU0u92rg+NderretTS1/XSFqfIv4jFUKtoaFBP/vZz9TY2KjVq1d/73xjjBwOh//x+X9uaU447dq1S88884x2797d5po6Wq+NjY2SpLvuuku//vWvJUnXX3+9SkpKtGbNGqWlpbV4bEfrVfp24SgtLdWmTZvUr18/bdu2TbNnz1ZCQoLGjh3b4nGR3uucOXP08ccfa/v27U32XVhTa+qM5H6/q1fJrvWpuV5tXZ+a69XW9aml7+FIWp8uqys2DQ0N+ulPf6qysjIVFhYGfHy62+1WfX29KisrA46pqKjw/9Todrt14sSJJuf93//93yY/WYbLu+++q4qKCvXt21dRUVGKiorS4cOHNW/ePPXv31+SPb327NlTUVFRGjJkSMD44MGD/b91YEuvdXV1euyxx7R8+XJNmjRJw4cP15w5c3Tvvffqn//5nyV1zF4feeQRbdq0SUVFRerTp49/3O12S1KTn9Iu7KUj9dtSr+fYtD611KuN61NLvdq4PrXUa8StT62+G6cDUTM3XtbX15vJkyeboUOHmoqKiibHnLux6dVXX/WPHTt2rNkbm95//33/nNLS0oi6yfTkyZNm7969AZvH4zELFizw12hLr8YYM2rUqCY3502ePNncd999xhh7eq2qqjKSzJtvvhkw75e//KXJyMgwxnSsXhsbG83DDz9sPB6P+eyzz5rd73a7zdKlS/1jPp+v2ZuHI73f7+vVGHvWp+/r1ab1qTVfV1vWp+/rNdLWJ2uCTU1Njfnoo4/MRx99ZCSZ5cuXm48++sgcPnzYNDQ0mDvvvNP06dPH7Nmzxxw/fty/+Xw+/zlmzZpl+vTpY95++22ze/duc9tttzX7q2jDhw83O3bsMDt27DDDhg275L8q+129NufC3zowxp5eCwoKTOfOnc0LL7xgDh06ZP71X//VdOrUybz77rvW9ZqWlmaGDh1qioqKzN/+9jezdu1a06VLF7N69eoO1+uvfvUrExcXZ7Zu3Rrw7/H06dP+OUuWLDFxcXGmoKDA7N2719x3333N/rp3pPf7fb3atD615ut6oY66PrWmV1vWp9b0GknrkzXBpqioyEhqss2YMcOUlZU1u0+SKSoq8p+jrq7OzJkzx/To0cPExMSYn/zkJ+bIkSMBz/Pll1+aadOmGZfLZVwul5k2bZqprKyMmF6b09zCYVOvL774ornmmmtMly5dzIgRIwLeN8EYe3o9fvy4eeCBB4zH4zFdunQx1157rfmXf/kX09jY6D9HR+m1pX+Pa9eu9c9pbGw0ixcvNm632zidTjN69Gizd+/egPN0hH6/r1eb1qfWfF0v1FHXp9b2asP61JpeI2l9cvy/ogEAADq8y+rmYQAAYDeCDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINgJCpqKjQzJkz1bdvXzmdTrndbo0fP147duyQJPXv318Oh6PJtmTJkoDzvP7660pPT1dcXJxiY2M1fPhwPfnkk/rqq6+Unp7e7DnObec+JTo9PV2ZmZkB5923b59++tOfqlevXnI6nUpKStLjjz+u06dPB8w7V2dpaWnAeGZmptLT00P6dwYgtKLCXQAAe9xzzz1qaGhQfn6+Bg4cqBMnTmjLli366quv/HOefPJJ/eIXvwg4zuVy+f+8aNEiLV26VL/+9a+Vm5srj8ejQ4cOac2aNfrTn/6kgoIC1dfXS5LKy8t100036e2339bQoUMlSZ06dWq2ttLSUo0dO1Zjx47Vn//8Z8XHx+uDDz7QvHnz9M4776ioqEjR0dH++V26dNGCBQtUXFwcsr8fAO2PYAMgJE6dOqXt27dr69atSktLkyT169dPN910U8A8l8slt9vd7Dk++OAD5ebmauXKlZo7d65/vH///srIyNCpU6d05ZVX+sfPnDkjSbr66qtbPKckGWP04IMPavDgwSooKNAVV1zhr2/QoEH6u7/7O61YsUILFizwHzNz5kw999xzevPNN3X77be37S8DQNjwUhSAkIiNjVVsbKw2btwon88X1DlefvllxcbGavbs2c3uPz/UtMWePXu0f/9+ZWVl+UPNOSNGjNDYsWP1yiuvBIz3799fs2bN0sKFC9XY2BjU8wK49Ag2AEIiKipK69atU35+vq688krdcssteuyxx/Txxx8HzFuwYIE/BJ3btm7dKkk6dOiQBg4cqM6dO4e0ts8++0ySNHjw4Gb3Dx482D/nfL/97W9VVlaml19+OaT1AGg/BBsAIXPPPffo2LFj2rRpk8aPH6+tW7fqRz/6kdatW+ef8+ijj2rPnj0BW0pKiqRvXzJyOByXvO6WnrdXr16aP3++nnjiCf99PQAiG8EGQEh16dJFGRkZeuKJJ1RSUqIHHnhAixcv9u/v2bOnrrnmmoAtJiZGkjRo0CD99a9/VUNDQ0hrGjRokCRp//79ze4/ePCgkpKSmt2XlZWluro6rV69OqQ1AWgfBBsA7WrIkCH6+uuvWzV36tSpqq2tbTFEnDp1Kqgarr/+el133XVasWJFk/tl/vu//1tvv/227rvvvmaPjY2N1eOPP66nn35a1dXVQT0/gEuHYAMgJL788kvddttt+vd//3d9/PHHKisr02uvvaZly5bprrvu8s+rqamR1+sN2M4FhpSUFGVnZ2vevHnKzs7Wjh07dPjwYW3ZskX/8A//oPz8/KBqczgc+uMf/6j9+/frnnvu0QcffKAjR47otdde06RJkzRq1Kgm73lzvl/+8peKi4trcoMxgMhDsAEQErGxsUpJSdGKFSs0evRoJScn6/HHH9cvfvELrVq1yj/viSeeUEJCQsCWnZ3t37906VKtX79e77//vsaPH6+hQ4cqKytLw4cP14wZM4Ku75ZbblFpaak6deqk22+/Xddcc40WLlyoGTNmqLCwUE6ns8VjO3furN///vf+Xy8HELkcxhgT7iIAAABCgSs2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALDG/wUe+aeixW+2oQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PRESENTAGE DISTRIBUTION OF ALL DATA SET\n",
    "\n",
    "print((df['SECTION'].value_counts()/df['SECTION'].count())*100)\n",
    "\n",
    "sns.histplot(df['SECTION'].value_counts(),stat='percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c9043c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGYCAYAAACzlLNPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfP0lEQVR4nO3df2xV9f3H8delhYKsPVJq7+2NF+wiss4SMqspbVTKr0Jj7QQT2JpVmQxUfqUrzIlkWbc5upkIJNQxxgjIL/EfUTNYpQTEdVDAbp3igGGEWGIvRVZuKetuEe73j8Xz9VJ+WKTevtvnIzkJ95z3vf0c75Y+c3pu64lEIhEBAAAY0yfWCwAAALgRRAwAADCJiAEAACYRMQAAwCQiBgAAmETEAAAAk4gYAABgEhEDAABMio/1ArrKpUuX9MknnygxMVEejyfWywEAAF9CJBLRuXPn5Pf71afPta+19NiI+eSTTxQIBGK9DAAAcAMaGhp0++23X3Omx0ZMYmKipP/9R0hKSorxagAAwJfR0tKiQCDgfh+/lh4bMZ//CCkpKYmIAQDAmC9zKwg39gIAAJOIGAAAYBIRAwAATCJiAACASUQMAAAwiYgBAAAmETEAAMAkIgYAAJhExAAAAJOIGAAAYBIRAwAATCJiAACASUQMAAAwiYgBAAAmxcd6AT3VHc9ui/USYuLEbx6K9RIAAL0EV2IAAIBJRAwAADCJiAEAACYRMQAAwCQiBgAAmETEAAAAk4gYAABgEhEDAABMImIAAIBJRAwAADCJiAEAACYRMQAAwCQiBgAAmETEAAAAk4gYAABgEhEDAABMImIAAIBJRAwAADCJiAEAACYRMQAAwCQiBgAAmETEAAAAk4gYAABgEhEDAABMImIAAIBJRAwAADCJiAEAACYRMQAAwCQiBgAAmETEAAAAkzoVMRUVFbrvvvuUmJio1NRUPfLIIzp69GjUzPTp0+XxeKK2UaNGRc2Ew2HNmzdPKSkpGjhwoIqKinTy5MmomebmZpWUlMhxHDmOo5KSEp09e/bGzhIAAPQ4nYqYPXv2aM6cOaqtrVV1dbU+++wz5efn6/z581FzkyZNUmNjo7tt37496nhpaam2bt2qLVu2qKamRq2trSosLNTFixfdmeLiYtXX16uqqkpVVVWqr69XSUnJVzhVAADQk8R3Zriqqirq8dq1a5Wamqq6ujo9+OCD7v6EhAT5fL4rvkYoFNKaNWu0YcMGjR8/XpK0ceNGBQIB7dy5UxMnTtThw4dVVVWl2tpaZWdnS5JWr16tnJwcHT16VMOHD+/USQIAgJ7nK90TEwqFJEnJyclR+99++22lpqbqrrvu0syZM9XU1OQeq6ur04ULF5Sfn+/u8/v9yszM1N69eyVJ+/btk+M4bsBI0qhRo+Q4jjtzuXA4rJaWlqgNAAD0XDccMZFIRGVlZbr//vuVmZnp7i8oKNCmTZu0a9cuvfjiizp48KDGjh2rcDgsSQoGg+rXr58GDRoU9Xper1fBYNCdSU1N7fA1U1NT3ZnLVVRUuPfPOI6jQCBwo6cGAAAM6NSPk75o7ty5eu+991RTUxO1f9q0ae6/MzMzde+992ro0KHatm2bpkyZctXXi0Qi8ng87uMv/vtqM1+0aNEilZWVuY9bWloIGQAAerAbuhIzb948vfnmm9q9e7duv/32a86mpaVp6NChOnbsmCTJ5/Opvb1dzc3NUXNNTU3yer3uzKlTpzq81unTp92ZyyUkJCgpKSlqAwAAPVenIiYSiWju3Ll67bXXtGvXLqWnp1/3OWfOnFFDQ4PS0tIkSVlZWerbt6+qq6vdmcbGRh06dEi5ubmSpJycHIVCIR04cMCd2b9/v0KhkDsDAAB6t079OGnOnDnavHmz3njjDSUmJrr3pziOowEDBqi1tVXl5eV69NFHlZaWphMnTui5555TSkqKJk+e7M7OmDFDCxYs0ODBg5WcnKyFCxdqxIgR7qeVMjIyNGnSJM2cOVOrVq2SJM2aNUuFhYV8MgkAAEjqZMSsXLlSkpSXlxe1f+3atZo+fbri4uL0/vvva/369Tp79qzS0tI0ZswYvfrqq0pMTHTnly1bpvj4eE2dOlVtbW0aN26c1q1bp7i4OHdm06ZNmj9/vvsppqKiIlVWVt7oeQIAgB7GE4lEIrFeRFdoaWmR4zgKhUIxuT/mjme3fe1fszs48ZuHYr0EAIBhnfn+zd9OAgAAJhExAADAJCIGAACYRMQAAACTiBgAAGASEQMAAEwiYgAAgElEDAAAMImIAQAAJhExAADAJCIGAACYRMQAAACTiBgAAGASEQMAAEwiYgAAgElEDAAAMImIAQAAJhExAADAJCIGAACYRMQAAACTiBgAAGASEQMAAEwiYgAAgElEDAAAMImIAQAAJhExAADAJCIGAACYRMQAAACTiBgAAGASEQMAAEwiYgAAgElEDAAAMImIAQAAJhExAADAJCIGAACYRMQAAACTiBgAAGASEQMAAEwiYgAAgElEDAAAMImIAQAAJhExAADAJCIGAACYRMQAAACTiBgAAGASEQMAAEwiYgAAgElEDAAAMImIAQAAJhExAADAJCIGAACYRMQAAACTOhUxFRUVuu+++5SYmKjU1FQ98sgjOnr0aNRMJBJReXm5/H6/BgwYoLy8PH3wwQdRM+FwWPPmzVNKSooGDhyooqIinTx5MmqmublZJSUlchxHjuOopKREZ8+evbGzBAAAPU6nImbPnj2aM2eOamtrVV1drc8++0z5+fk6f/68O/PCCy9o6dKlqqys1MGDB+Xz+TRhwgSdO3fOnSktLdXWrVu1ZcsW1dTUqLW1VYWFhbp48aI7U1xcrPr6elVVVamqqkr19fUqKSm5CacMAAB6Ak8kEonc6JNPnz6t1NRU7dmzRw8++KAikYj8fr9KS0v105/+VNL/rrp4vV799re/1ZNPPqlQKKTbbrtNGzZs0LRp0yRJn3zyiQKBgLZv366JEyfq8OHD+va3v63a2lplZ2dLkmpra5WTk6MjR45o+PDh111bS0uLHMdRKBRSUlLSjZ7iDbvj2W1f+9fsDk785qFYLwEAYFhnvn9/pXtiQqGQJCk5OVmSdPz4cQWDQeXn57szCQkJGj16tPbu3StJqqur04ULF6Jm/H6/MjMz3Zl9+/bJcRw3YCRp1KhRchzHnblcOBxWS0tL1AYAAHquG46YSCSisrIy3X///crMzJQkBYNBSZLX642a9Xq97rFgMKh+/fpp0KBB15xJTU3t8DVTU1PdmctVVFS49884jqNAIHCjpwYAAAy44YiZO3eu3nvvPb3yyisdjnk8nqjHkUikw77LXT5zpflrvc6iRYsUCoXcraGh4cucBgAAMOqGImbevHl68803tXv3bt1+++3ufp/PJ0kdrpY0NTW5V2d8Pp/a29vV3Nx8zZlTp051+LqnT5/ucJXncwkJCUpKSoraAABAz9WpiIlEIpo7d65ee+017dq1S+np6VHH09PT5fP5VF1d7e5rb2/Xnj17lJubK0nKyspS3759o2YaGxt16NAhdyYnJ0ehUEgHDhxwZ/bv369QKOTOAACA3i2+M8Nz5szR5s2b9cYbbygxMdG94uI4jgYMGCCPx6PS0lItWbJEw4YN07Bhw7RkyRLdcsstKi4udmdnzJihBQsWaPDgwUpOTtbChQs1YsQIjR8/XpKUkZGhSZMmaebMmVq1apUkadasWSosLPxSn0wCAAA9X6ciZuXKlZKkvLy8qP1r167V9OnTJUnPPPOM2traNHv2bDU3Nys7O1s7duxQYmKiO79s2TLFx8dr6tSpamtr07hx47Ru3TrFxcW5M5s2bdL8+fPdTzEVFRWpsrLyRs4RAAD0QF/p98R0Z/yemNjg98QAAL6Kr+33xAAAAMQKEQMAAEwiYgAAgEmdurEXwJVxDxQAfP24EgMAAEwiYgAAgElEDAAAMImIAQAAJhExAADAJCIGAACYRMQAAACTiBgAAGASEQMAAEwiYgAAgElEDAAAMImIAQAAJhExAADAJCIGAACYRMQAAACTiBgAAGASEQMAAEwiYgAAgElEDAAAMImIAQAAJhExAADAJCIGAACYRMQAAACTiBgAAGASEQMAAEwiYgAAgElEDAAAMImIAQAAJhExAADApPhYLwAArLnj2W2xXkJMnPjNQ7FeAhCFKzEAAMAkIgYAAJhExAAAAJOIGAAAYBIRAwAATCJiAACASUQMAAAwiYgBAAAmETEAAMAkIgYAAJhExAAAAJOIGAAAYBIRAwAATCJiAACASUQMAAAwiYgBAAAmETEAAMAkIgYAAJhExAAAAJM6HTHvvPOOHn74Yfn9fnk8Hr3++utRx6dPny6PxxO1jRo1KmomHA5r3rx5SklJ0cCBA1VUVKSTJ09GzTQ3N6ukpESO48hxHJWUlOjs2bOdPkEAANAzdTpizp8/r5EjR6qysvKqM5MmTVJjY6O7bd++Pep4aWmptm7dqi1btqimpkatra0qLCzUxYsX3Zni4mLV19erqqpKVVVVqq+vV0lJSWeXCwAAeqj4zj6hoKBABQUF15xJSEiQz+e74rFQKKQ1a9Zow4YNGj9+vCRp48aNCgQC2rlzpyZOnKjDhw+rqqpKtbW1ys7OliStXr1aOTk5Onr0qIYPH97ZZQMAgB6mS+6Jefvtt5Wamqq77rpLM2fOVFNTk3usrq5OFy5cUH5+vrvP7/crMzNTe/fulSTt27dPjuO4ASNJo0aNkuM47szlwuGwWlpaojYAANBz3fSIKSgo0KZNm7Rr1y69+OKLOnjwoMaOHatwOCxJCgaD6tevnwYNGhT1PK/Xq2Aw6M6kpqZ2eO3U1FR35nIVFRXu/TOO4ygQCNzkMwMAAN1Jp3+cdD3Tpk1z/52Zmal7771XQ4cO1bZt2zRlypSrPi8Sicjj8biPv/jvq8180aJFi1RWVuY+bmlpIWQAAOjBuvwj1mlpaRo6dKiOHTsmSfL5fGpvb1dzc3PUXFNTk7xerztz6tSpDq91+vRpd+ZyCQkJSkpKitoAAEDP1eURc+bMGTU0NCgtLU2SlJWVpb59+6q6utqdaWxs1KFDh5SbmytJysnJUSgU0oEDB9yZ/fv3KxQKuTMAAKB36/SPk1pbW/Xhhx+6j48fP676+nolJycrOTlZ5eXlevTRR5WWlqYTJ07oueeeU0pKiiZPnixJchxHM2bM0IIFCzR48GAlJydr4cKFGjFihPtppYyMDE2aNEkzZ87UqlWrJEmzZs1SYWEhn0wCAACSbiBi3n33XY0ZM8Z9/Pl9KI8//rhWrlyp999/X+vXr9fZs2eVlpamMWPG6NVXX1ViYqL7nGXLlik+Pl5Tp05VW1ubxo0bp3Xr1ikuLs6d2bRpk+bPn+9+iqmoqOiav5sGAAD0Lp2OmLy8PEUikasef+utt677Gv3799eKFSu0YsWKq84kJydr48aNnV0eAADoJfjbSQAAwCQiBgAAmETEAAAAk4gYAABgEhEDAABMImIAAIBJRAwAADCJiAEAACYRMQAAwCQiBgAAmETEAAAAk4gYAABgEhEDAABMImIAAIBJRAwAADCJiAEAACYRMQAAwCQiBgAAmETEAAAAk4gYAABgEhEDAABMImIAAIBJRAwAADCJiAEAACYRMQAAwKT4WC8AAIDu7I5nt8V6CTFx4jcPxXoJ18WVGAAAYBIRAwAATCJiAACASUQMAAAwiYgBAAAmETEAAMAkIgYAAJhExAAAAJOIGAAAYBIRAwAATCJiAACASUQMAAAwiYgBAAAmETEAAMAkIgYAAJhExAAAAJOIGAAAYBIRAwAATCJiAACASUQMAAAwiYgBAAAmETEAAMAkIgYAAJhExAAAAJOIGAAAYBIRAwAATOp0xLzzzjt6+OGH5ff75fF49Prrr0cdj0QiKi8vl9/v14ABA5SXl6cPPvggaiYcDmvevHlKSUnRwIEDVVRUpJMnT0bNNDc3q6SkRI7jyHEclZSU6OzZs50+QQAA0DN1OmLOnz+vkSNHqrKy8orHX3jhBS1dulSVlZU6ePCgfD6fJkyYoHPnzrkzpaWl2rp1q7Zs2aKamhq1traqsLBQFy9edGeKi4tVX1+vqqoqVVVVqb6+XiUlJTdwigAAoCeK7+wTCgoKVFBQcMVjkUhEy5cv1+LFizVlyhRJ0ssvvyyv16vNmzfrySefVCgU0po1a7RhwwaNHz9ekrRx40YFAgHt3LlTEydO1OHDh1VVVaXa2lplZ2dLklavXq2cnBwdPXpUw4cPv9HzBQAAPcRNvSfm+PHjCgaDys/Pd/clJCRo9OjR2rt3rySprq5OFy5ciJrx+/3KzMx0Z/bt2yfHcdyAkaRRo0bJcRx35nLhcFgtLS1RGwAA6LluasQEg0FJktfrjdrv9XrdY8FgUP369dOgQYOuOZOamtrh9VNTU92Zy1VUVLj3zziOo0Ag8JXPBwAAdF9d8ukkj8cT9TgSiXTYd7nLZ640f63XWbRokUKhkLs1NDTcwMoBAIAVNzVifD6fJHW4WtLU1ORenfH5fGpvb1dzc/M1Z06dOtXh9U+fPt3hKs/nEhISlJSUFLUBAICe66ZGTHp6unw+n6qrq9197e3t2rNnj3JzcyVJWVlZ6tu3b9RMY2OjDh065M7k5OQoFArpwIED7sz+/fsVCoXcGQAA0Lt1+tNJra2t+vDDD93Hx48fV319vZKTkzVkyBCVlpZqyZIlGjZsmIYNG6YlS5bolltuUXFxsSTJcRzNmDFDCxYs0ODBg5WcnKyFCxdqxIgR7qeVMjIyNGnSJM2cOVOrVq2SJM2aNUuFhYV8MgkAAEi6gYh59913NWbMGPdxWVmZJOnxxx/XunXr9Mwzz6itrU2zZ89Wc3OzsrOztWPHDiUmJrrPWbZsmeLj4zV16lS1tbVp3LhxWrduneLi4tyZTZs2af78+e6nmIqKiq76u2kAAEDv0+mIycvLUyQSuepxj8ej8vJylZeXX3Wmf//+WrFihVasWHHVmeTkZG3cuLGzywMAAL0EfzsJAACYRMQAAACTiBgAAGASEQMAAEwiYgAAgElEDAAAMImIAQAAJhExAADAJCIGAACYRMQAAACTiBgAAGASEQMAAEwiYgAAgElEDAAAMImIAQAAJhExAADAJCIGAACYRMQAAACTiBgAAGASEQMAAEwiYgAAgElEDAAAMImIAQAAJhExAADAJCIGAACYRMQAAACTiBgAAGASEQMAAEwiYgAAgElEDAAAMImIAQAAJhExAADAJCIGAACYRMQAAACTiBgAAGASEQMAAEwiYgAAgElEDAAAMImIAQAAJhExAADAJCIGAACYRMQAAACTiBgAAGASEQMAAEwiYgAAgElEDAAAMImIAQAAJhExAADAJCIGAACYRMQAAACTiBgAAGASEQMAAEwiYgAAgEk3PWLKy8vl8XiiNp/P5x6PRCIqLy+X3+/XgAEDlJeXpw8++CDqNcLhsObNm6eUlBQNHDhQRUVFOnny5M1eKgAAMKxLrsTcfffdamxsdLf333/fPfbCCy9o6dKlqqys1MGDB+Xz+TRhwgSdO3fOnSktLdXWrVu1ZcsW1dTUqLW1VYWFhbp48WJXLBcAABgU3yUvGh8fdfXlc5FIRMuXL9fixYs1ZcoUSdLLL78sr9erzZs368knn1QoFNKaNWu0YcMGjR8/XpK0ceNGBQIB7dy5UxMnTuyKJQMAAGO65ErMsWPH5Pf7lZ6eru9973v66KOPJEnHjx9XMBhUfn6+O5uQkKDRo0dr7969kqS6ujpduHAhasbv9yszM9OduZJwOKyWlpaoDQAA9Fw3PWKys7O1fv16vfXWW1q9erWCwaByc3N15swZBYNBSZLX6416jtfrdY8Fg0H169dPgwYNuurMlVRUVMhxHHcLBAI3+cwAAEB3ctMjpqCgQI8++qhGjBih8ePHa9u2bZL+92Ojz3k8nqjnRCKRDvsud72ZRYsWKRQKuVtDQ8NXOAsAANDddflHrAcOHKgRI0bo2LFj7n0yl19RaWpqcq/O+Hw+tbe3q7m5+aozV5KQkKCkpKSoDQAA9FxdHjHhcFiHDx9WWlqa0tPT5fP5VF1d7R5vb2/Xnj17lJubK0nKyspS3759o2YaGxt16NAhdwYAAOCmfzpp4cKFevjhhzVkyBA1NTXp+eefV0tLix5//HF5PB6VlpZqyZIlGjZsmIYNG6YlS5bolltuUXFxsSTJcRzNmDFDCxYs0ODBg5WcnKyFCxe6P54CAACQuiBiTp48qe9///v69NNPddttt2nUqFGqra3V0KFDJUnPPPOM2traNHv2bDU3Nys7O1s7duxQYmKi+xrLli1TfHy8pk6dqra2No0bN07r1q1TXFzczV4uAAAw6qZHzJYtW6553OPxqLy8XOXl5Ved6d+/v1asWKEVK1bc5NUBAICegr+dBAAATCJiAACASUQMAAAwiYgBAAAmETEAAMAkIgYAAJhExAAAAJOIGAAAYBIRAwAATCJiAACASUQMAAAwiYgBAAAmETEAAMAkIgYAAJhExAAAAJOIGAAAYBIRAwAATCJiAACASUQMAAAwiYgBAAAmETEAAMAkIgYAAJhExAAAAJOIGAAAYBIRAwAATCJiAACASUQMAAAwiYgBAAAmETEAAMAkIgYAAJhExAAAAJOIGAAAYBIRAwAATCJiAACASUQMAAAwiYgBAAAmETEAAMAkIgYAAJhExAAAAJOIGAAAYBIRAwAATCJiAACASUQMAAAwiYgBAAAmETEAAMAkIgYAAJhExAAAAJOIGAAAYBIRAwAATCJiAACASUQMAAAwiYgBAAAmdfuI+d3vfqf09HT1799fWVlZ+stf/hLrJQEAgG6gW0fMq6++qtLSUi1evFh///vf9cADD6igoEAff/xxrJcGAABirFtHzNKlSzVjxgz96Ec/UkZGhpYvX65AIKCVK1fGemkAACDG4mO9gKtpb29XXV2dnn322aj9+fn52rt3b4f5cDiscDjsPg6FQpKklpaWrl3oVVwK/ycmXzfWYvXfO9Z4v3sX3u/ehfc7Nl83Eolcd7bbRsynn36qixcvyuv1Ru33er0KBoMd5isqKvSLX/yiw/5AINBla0RHzvJYrwBfJ97v3oX3u3eJ9ft97tw5OY5zzZluGzGf83g8UY8jkUiHfZK0aNEilZWVuY8vXbqkf//73xo8ePAV53uqlpYWBQIBNTQ0KCkpKdbLQRfj/e5deL97l976fkciEZ07d05+v/+6s902YlJSUhQXF9fhqktTU1OHqzOSlJCQoISEhKh9t956a1cusVtLSkrqVf+j7+14v3sX3u/epTe+39e7AvO5bntjb79+/ZSVlaXq6uqo/dXV1crNzY3RqgAAQHfRba/ESFJZWZlKSkp07733KicnR3/4wx/08ccf66mnnor10gAAQIx164iZNm2azpw5o1/+8pdqbGxUZmamtm/frqFDh8Z6ad1WQkKCfv7zn3f40Rp6Jt7v3oX3u3fh/b4+T+TLfIYJAACgm+m298QAAABcCxEDAABMImIAAIBJRAwAADCJiAEAACZ1649YA0BvdvLkSa1cuVJ79+5VMBiUx+OR1+tVbm6unnrqKf42HHo9rsT0cA0NDXriiSdivQzcJG1tbaqpqdE///nPDsf++9//av369TFYFbpCTU2NMjIytHXrVo0cOVKPPfaYfvCDH2jkyJF6/fXXdffdd+uvf/1rrJeJm+jw4cNau3atjhw5Ikk6cuSInn76aT3xxBPatWtXjFfXPfF7Ynq4f/zjH7rnnnt08eLFWC8FX9G//vUv5efn6+OPP5bH49EDDzygV155RWlpaZKkU6dOye/38173EPfdd5/uv/9+LVu27IrHf/zjH6umpkYHDx78mleGrlBVVaXvfve7+sY3vqH//Oc/2rp1qx577DGNHDlSkUhEe/bs0VtvvaWxY8fGeqndChFj3JtvvnnN4x999JEWLFjAN7YeYPLkyfrss8+0du1anT17VmVlZTp06JDefvttDRkyhIjpYQYMGKD6+noNHz78isePHDmi73znO2pra/uaV4aukJubq7Fjx+r555/Xli1bNHv2bD399NP69a9/LUlavHixDh48qB07dsR4pd0LEWNcnz595PF4dK230ePx8I2tB/B6vdq5c6dGjBjh7pszZ47+9Kc/affu3Ro4cCAR04N885vf1M9+9jP98Ic/vOLxtWvX6le/+pU++uijr3ll6AqO46iurk533nmnLl26pISEBO3fv1/33HOPJOnQoUMaP368gsFgjFfavXBjr3FpaWl66aWX9Mgjj1zxeH19vbKysr7eRaFLtLW1KT4++v+yL730kvr06aPRo0dr8+bNMVoZusLChQv11FNPqa6uThMmTJDX65XH41EwGFR1dbX++Mc/avny5bFeJrpAnz591L9/f916663uvsTERIVCodgtqpsiYozLysrS3/72t6tGzPWu0sCOb33rW3r33XeVkZERtX/FihWKRCIqKiqK0crQFWbPnq3Bgwdr2bJlWrVqlXuFLS4uTllZWVq/fr2mTp0a41XiZrnjjjv04Ycf6s4775Qk7du3T0OGDHGPNzQ0uPe/4f8RMcb95Cc/0fnz5696/M4779Tu3bu/xhWhq0yePFmvvPKKSkpKOhyrrKzUpUuX9Pvf/z4GK0NXmTZtmqZNm6YLFy7o008/lSSlpKSob9++MV4Zbrann3466kfBmZmZUcf//Oc/c1PvFXBPDAAAMInfEwMAAEwiYgAAgElEDAAAMImIAQAAJhExAADAJCIGAACYRMQAAACTiBgAAGDS/wFc6XK0zx8O5gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['SECTION'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54f134e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">STORY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SECTION</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1686</td>\n",
       "      <td>1673</td>\n",
       "      <td>This story has been published from a wire agen...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2772</td>\n",
       "      <td>2731</td>\n",
       "      <td>This story has been published from a wire agen...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1924</td>\n",
       "      <td>1914</td>\n",
       "      <td>The consensus reads, “Exciting, entertaining, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1246</td>\n",
       "      <td>1233</td>\n",
       "      <td>This story has been published from a wire agen...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        STORY                                                               \n",
       "        count unique                                                top freq\n",
       "SECTION                                                                     \n",
       "0        1686   1673  This story has been published from a wire agen...    4\n",
       "1        2772   2731  This story has been published from a wire agen...   13\n",
       "2        1924   1914  The consensus reads, “Exciting, entertaining, ...    3\n",
       "3        1246   1233  This story has been published from a wire agen...   11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('SECTION').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0db59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9c941d2",
   "metadata": {},
   "source": [
    "# TEXT PreProcessing Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bb2679c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "      <th>SECTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But the most painful was the huge reversal in ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How formidable is the opposition alliance amon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most Asian currencies were trading lower today...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you want to answer any question, click on ‘...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In global markets, gold prices edged up today ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               STORY  SECTION\n",
       "0  But the most painful was the huge reversal in ...        3\n",
       "1  How formidable is the opposition alliance amon...        0\n",
       "2  Most Asian currencies were trading lower today...        3\n",
       "3  If you want to answer any question, click on ‘...        1\n",
       "4  In global markets, gold prices edged up today ...        3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing the punctuation\n",
    "#removing the stopwords \n",
    "#removing the null values\n",
    "#removing the numbers\n",
    "#removing the html links tags\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "174f19dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"BEIJING: Chinese tech giant Huawei has announced plans to release a next-generation smartphone based on its own technology instead of US components, stepping up efforts to compete directly with Western industry leaders.\\n\\n\\nThursday's announcement comes as Huawei Technologies Ltd., the world's biggest maker of network gear for phone companies, combats US warnings the company might be a security risk.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['STORY'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987fb790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb7a7bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\" # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def pre_process(text):\n",
    "    \n",
    "    #removing the punctuation\n",
    "    text=[char for char in text if char not in string.punctuation]\n",
    "    text=''.join(text)\n",
    "    \n",
    "    #removing the number\n",
    "    text =re.sub('[0-9]','',text)\n",
    "    \n",
    "    #removing the stopwords\n",
    "    no_stop=[word for word in text.split() if word not in stopwords.words('english')]\n",
    "    \n",
    "    no_stop=' '.join(no_stop)\n",
    "    \n",
    "    \n",
    "    #doing the lemaatization\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    \n",
    "    #it will split the sentence into the words\n",
    "    word_tokens = word_tokenize(no_stop)\n",
    "    fin_txt =' '.join([lemmatizer.lemmatize(word) for word in word_tokens]) \n",
    "    \n",
    "    \n",
    "    return fin_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14df09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7de13d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the preprocess\n",
    "df['STORY'] = df['STORY'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb7b7c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "      <th>SECTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>Expect new iPads priced notch higher previous ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>In statement US medium Samsung said initial fi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>As Jaaved Jaaferi brought house Feroz Khan car...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162</th>\n",
       "      <td>The character movie created new timeline went ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4570</th>\n",
       "      <td>Chris Hemsworth expressed interest playing Mar...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  STORY  SECTION\n",
       "3058  Expect new iPads priced notch higher previous ...        1\n",
       "2960  In statement US medium Samsung said initial fi...        1\n",
       "569   As Jaaved Jaaferi brought house Feroz Khan car...        2\n",
       "5162  The character movie created new timeline went ...        2\n",
       "4570  Chris Hemsworth expressed interest playing Mar...        2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2d35f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['STORY']=df['STORY'].apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0976cdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happiest happy  mind heart light heaven Happy happy joy joy unique Artist boy I know never changing sooooproud Ridzajaanturns loveyoumadly ” Sussanne Khan wrote along video'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['STORY'][5858]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35b27042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STORY      0\n",
       "SECTION    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6454042c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e1594b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "888ef228",
   "metadata": {},
   "source": [
    "# Feature Engineering or Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e96ef47",
   "metadata": {},
   "source": [
    "<b>Genrate the custom column</b>\n",
    "<ol>length of text</ol>\n",
    "<ol>Total word</ol>\n",
    "<ol>Normaliation</ol>\n",
    "<ol></ol>\n",
    "<ol></ol>\n",
    "<ol></ol>\n",
    "<ol></ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33366fe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "      <th>SECTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>Devotees throng street Nagpur celebrate annual...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6591</th>\n",
       "      <td>Apple longer break detailed number iPhone ship...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>He enjoyed screentime followed quest gain Infi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5782</th>\n",
       "      <td>In statement RCom said ₹ crore due Ericsson in...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  STORY  SECTION\n",
       "2289  Devotees throng street Nagpur celebrate annual...        0\n",
       "6591  Apple longer break detailed number iPhone ship...        1\n",
       "1495  He enjoyed screentime followed quest gain Infi...        2\n",
       "5782  In statement RCom said ₹ crore due Ericsson in...        3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa6a7abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df['STORY'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2cabe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lebgth of text\n",
    "df['length_text'] = df['STORY'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "056d6fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>length_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But painful huge reversal fee income unheard a...</td>\n",
       "      <td>3</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How formidable opposition alliance among Congr...</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most Asian currency trading lower today South ...</td>\n",
       "      <td>3</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If want answer question click ‘ Answer ’ After...</td>\n",
       "      <td>1</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In global market gold price edged today disapp...</td>\n",
       "      <td>3</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               STORY  SECTION  length_text\n",
       "0  But painful huge reversal fee income unheard a...        3          574\n",
       "1  How formidable opposition alliance among Congr...        0          112\n",
       "2  Most Asian currency trading lower today South ...        3          241\n",
       "3  If want answer question click ‘ Answer ’ After...        1          383\n",
       "4  In global market gold price edged today disapp...        3          245"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9c95319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'But painful huge reversal fee income unheard among private sector lender Essentially mean Yes Bank took granted fee structured loan deal paid accounted upfront book As borrower turned defaulter fee tied loan deal fell crack Gill vowed shift safer accounting practice amortizing fee income rather booking upfront Gill ’ s move mend past way mean nasty surprise future This good news considering investor love clean image loathe uncertainty But gain without pain promise strong stable balance sheet come sacrifice well Investors give hope phenomenal growth promise made Kapoor'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['STORY'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75688731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[count(word) for word in df['STORY'][0].split()]\n",
    "\n",
    "df['word_length'] = df['STORY'].apply(lambda row:len(row.split(' ')) if not pd.isnull(row) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "723395b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_length'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aee6c602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3570    Tamilrockers successfully evaded authority als...\n",
       "Name: STORY, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['word_length']==7]['STORY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "624511e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tamilrockers successfully evaded authority also acquired audience'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['STORY'][3570]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a534e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>length_text</th>\n",
       "      <th>word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But painful huge reversal fee income unheard a...</td>\n",
       "      <td>3</td>\n",
       "      <td>574</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How formidable opposition alliance among Congr...</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most Asian currency trading lower today South ...</td>\n",
       "      <td>3</td>\n",
       "      <td>241</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If want answer question click ‘ Answer ’ After...</td>\n",
       "      <td>1</td>\n",
       "      <td>383</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In global market gold price edged today disapp...</td>\n",
       "      <td>3</td>\n",
       "      <td>245</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               STORY  SECTION  length_text  \\\n",
       "0  But painful huge reversal fee income unheard a...        3          574   \n",
       "1  How formidable opposition alliance among Congr...        0          112   \n",
       "2  Most Asian currency trading lower today South ...        3          241   \n",
       "3  If want answer question click ‘ Answer ’ After...        1          383   \n",
       "4  In global market gold price edged today disapp...        3          245   \n",
       "\n",
       "   word_length  \n",
       "0           88  \n",
       "1           14  \n",
       "2           35  \n",
       "3           61  \n",
       "4           36  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4593ff8f",
   "metadata": {},
   "source": [
    "# EDA to Check the created column will help in prediction or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb2f2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c03eb99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='length_text', ylabel='Percent'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df,x=df['length_text'],hue=df['SECTION'],stat='percent',palette='pastel',log_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "586f0cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.histplot(data=df,x=df['word_length'],hue=df['SECTION'],stat='percent',palette='pastel',log_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58142f09",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "converting text data into the vector formet to better understand by our model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d81f0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'But painful huge reversal fee income unheard among private sector lender Essentially mean Yes Bank took granted fee structured loan deal paid accounted upfront book As borrower turned defaulter fee tied loan deal fell crack Gill vowed shift safer accounting practice amortizing fee income rather booking upfront Gill ’ s move mend past way mean nasty surprise future This good news considering investor love clean image loathe uncertainty But gain without pain promise strong stable balance sheet come sacrifice well Investors give hope phenomenal growth promise made Kapoor'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['STORY'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81b6d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "001962d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'But painful huge reversal fee income unheard among private sector lender Essentially mean Yes Bank took granted fee structured loan deal paid accounted upfront book As borrower turned defaulter fee tied loan deal fell crack Gill vowed shift safer accounting practice amortizing fee income rather booking upfront Gill ’ s move mend past way mean nasty surprise future This good news considering investor love clean image loathe uncertainty But gain without pain promise strong stable balance sheet come sacrifice well Investors give hope phenomenal growth promise made Kapoor'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['STORY'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b74ecc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#final function which wil use in the vectorization step\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def text_pre_process(text):\n",
    "    \n",
    "    #removing the punctuation\n",
    "    text=[char for char in text if char not in string.punctuation]\n",
    "    text=''.join(text)\n",
    "    \n",
    "    #removing the number\n",
    "    text =re.sub('[0-9]','',text)\n",
    "    \n",
    "    #removing the stopwords\n",
    "    no_stop=[word for word in text.split() if word not in stopwords.words('english')]\n",
    "    \n",
    "    no_stop=' '.join(no_stop)\n",
    "    \n",
    "    #removing the emoji in the text\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\" # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    rem_emooji_text = emoji_pattern.sub(r'', no_stop)\n",
    "\n",
    "    \n",
    "    #doing the lemaatization\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    \n",
    "    #it will split the sentence into the words\n",
    "    word_tokens = word_tokenize(rem_emooji_text)\n",
    "    fin_txt =[lemmatizer.lemmatize(word) for word in word_tokens] \n",
    "    \n",
    "    \n",
    "    return fin_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ad6253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "beeab6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happiest happy  mind heart light heaven Happy happy joy joy unique Artist boy I know never changing sooooproud Ridzajaanturns loveyoumadly ” Sussanne Khan wrote along video'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(df['STORY'][5858])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c335556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happiest happy  mind heart light heaven Happy happy joy joy unique Artist boy I know never changing sooooproud Ridzajaanturns loveyoumadly ” Sussanne Khan wrote along video'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['STORY'][5858]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb66c73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>length_text</th>\n",
       "      <th>word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But painful huge reversal fee income unheard a...</td>\n",
       "      <td>3</td>\n",
       "      <td>574</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How formidable opposition alliance among Congr...</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most Asian currency trading lower today South ...</td>\n",
       "      <td>3</td>\n",
       "      <td>241</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If want answer question click ‘ Answer ’ After...</td>\n",
       "      <td>1</td>\n",
       "      <td>383</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In global market gold price edged today disapp...</td>\n",
       "      <td>3</td>\n",
       "      <td>245</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               STORY  SECTION  length_text  \\\n",
       "0  But painful huge reversal fee income unheard a...        3          574   \n",
       "1  How formidable opposition alliance among Congr...        0          112   \n",
       "2  Most Asian currency trading lower today South ...        3          241   \n",
       "3  If want answer question click ‘ Answer ’ After...        1          383   \n",
       "4  In global market gold price edged today disapp...        3          245   \n",
       "\n",
       "   word_length  \n",
       "0           88  \n",
       "1           14  \n",
       "2           35  \n",
       "3           61  \n",
       "4           36  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad5a886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now creating the word vectorizer algorithm to work\n",
    "\n",
    "#DOING THE bag of words vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow_transformer = CountVectorizer(analyzer=text_pre_process).fit(df['STORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c689763d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(analyzer=&lt;function text_pre_process at 0x000001922A2CC2C0&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer=&lt;function text_pre_process at 0x000001922A2CC2C0&gt;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(analyzer=<function text_pre_process at 0x000001922A2CC2C0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "893c343e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37366"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#THIS IS THE NUMBER OF TOTAL UNIQUE WORDS IN THE WHOLE CORPUS\n",
    "\n",
    "len(bow_transformer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6b94b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'But': 2243,\n",
       " 'painful': 29325,\n",
       " 'huge': 25150,\n",
       " 'reversal': 31917,\n",
       " 'fee': 23276,\n",
       " 'income': 25552,\n",
       " 'unheard': 35938,\n",
       " 'among': 16971,\n",
       " 'private': 30504,\n",
       " 'sector': 32587,\n",
       " 'lender': 26752,\n",
       " 'Essentially': 4544,\n",
       " 'mean': 27473,\n",
       " 'Yes': 16135,\n",
       " 'Bank': 1482,\n",
       " 'took': 35238,\n",
       " 'granted': 24387,\n",
       " 'structured': 34204,\n",
       " 'loan': 26961,\n",
       " 'deal': 20832,\n",
       " 'paid': 29320,\n",
       " 'accounted': 16436,\n",
       " 'upfront': 36145,\n",
       " 'book': 18367,\n",
       " 'As': 993,\n",
       " 'borrower': 18408,\n",
       " 'turned': 35629,\n",
       " 'defaulter': 20961,\n",
       " 'tied': 35118,\n",
       " 'fell': 23289,\n",
       " 'crack': 20404,\n",
       " 'Gill': 5443,\n",
       " 'vowed': 36591,\n",
       " 'shift': 32902,\n",
       " 'safer': 32247,\n",
       " 'accounting': 16437,\n",
       " 'practice': 30213,\n",
       " 'amortizing': 16979,\n",
       " 'rather': 31079,\n",
       " 'booking': 18369,\n",
       " '’': 37346,\n",
       " 'move': 28078,\n",
       " 'mend': 27565,\n",
       " 'past': 29471,\n",
       " 'way': 36733,\n",
       " 'nasty': 28275,\n",
       " 'surprise': 34479,\n",
       " 'future': 23999,\n",
       " 'This': 14573,\n",
       " 'good': 24302,\n",
       " 'news': 28426,\n",
       " 'considering': 20027,\n",
       " 'investor': 26118,\n",
       " 'love': 27094,\n",
       " 'clean': 19414,\n",
       " 'image': 25373,\n",
       " 'loathe': 26964,\n",
       " 'uncertainty': 35772,\n",
       " 'gain': 24021,\n",
       " 'without': 36991,\n",
       " 'pain': 29323,\n",
       " 'promise': 30651,\n",
       " 'strong': 34190,\n",
       " 'stable': 33828,\n",
       " 'balance': 17768,\n",
       " 'sheet': 32890,\n",
       " 'come': 19663,\n",
       " 'sacrifice': 32230,\n",
       " 'well': 36807,\n",
       " 'Investors': 6768,\n",
       " 'give': 24207,\n",
       " 'hope': 25072,\n",
       " 'phenomenal': 29720,\n",
       " 'growth': 24493,\n",
       " 'made': 27214,\n",
       " 'Kapoor': 7437,\n",
       " 'How': 6213,\n",
       " 'formidable': 23755,\n",
       " 'opposition': 29005,\n",
       " 'alliance': 16852,\n",
       " 'Congress': 3155,\n",
       " 'Jharkhand': 7111,\n",
       " 'Mukti': 9516,\n",
       " 'Morcha': 9424,\n",
       " 'JMM': 6869,\n",
       " 'Vikas': 15475,\n",
       " 'Prajatantrik': 11304,\n",
       " 'Most': 9444,\n",
       " 'Asian': 1026,\n",
       " 'currency': 20620,\n",
       " 'trading': 35351,\n",
       " 'lower': 27114,\n",
       " 'today': 35193,\n",
       " 'South': 13629,\n",
       " 'Korean': 7816,\n",
       " 'China': 2781,\n",
       " 'renminbi': 31604,\n",
       " 'Offshore': 10311,\n",
       " 'Malaysian': 8711,\n",
       " 'ringgit': 32029,\n",
       " 'Indonesian': 6616,\n",
       " 'rupiah': 32208,\n",
       " 'Taiwan': 14281,\n",
       " 'dollar': 21816,\n",
       " 'However': 6216,\n",
       " 'Japanese': 7008,\n",
       " 'yen': 37196,\n",
       " 'The': 14519,\n",
       " 'index': 25599,\n",
       " 'measure': 27484,\n",
       " 'US': 14991,\n",
       " 'strength': 34155,\n",
       " 'major': 27266,\n",
       " 'previous': 30417,\n",
       " 'close': 19476,\n",
       " 'If': 6453,\n",
       " 'want': 36649,\n",
       " 'answer': 17092,\n",
       " 'question': 30927,\n",
       " 'click': 19440,\n",
       " '‘': 37345,\n",
       " 'Answer': 804,\n",
       " 'After': 370,\n",
       " 'clicking': 19443,\n",
       " 'also': 16909,\n",
       " 'check': 19226,\n",
       " 'reply': 31651,\n",
       " 'user': 36233,\n",
       " 'Proceed': 11430,\n",
       " 'either': 22251,\n",
       " 'writing': 37129,\n",
       " 'voice': 36544,\n",
       " 'command': 19680,\n",
       " 'ask': 17393,\n",
       " '“': 37347,\n",
       " 'Ask': 1034,\n",
       " 'A': 0,\n",
       " 'Question': 11618,\n",
       " 'Few': 4885,\n",
       " 'prefix': 30298,\n",
       " 'already': 16906,\n",
       " 'inserted': 25828,\n",
       " 'help': 24843,\n",
       " 'submitting': 34276,\n",
       " 'app': 17206,\n",
       " 'send': 32715,\n",
       " 'neighbour': 28364,\n",
       " 'let': 26771,\n",
       " 'know': 26464,\n",
       " 'many': 27346,\n",
       " 'asked': 17394,\n",
       " 'Click': 2961,\n",
       " 'Done': 4034,\n",
       " 'You': 16169,\n",
       " 'bell': 18000,\n",
       " 'icon': 25293,\n",
       " 'homepage': 25037,\n",
       " 'follow': 23653,\n",
       " 'In': 6502,\n",
       " 'global': 24244,\n",
       " 'market': 27369,\n",
       " 'gold': 24293,\n",
       " 'price': 30421,\n",
       " 'edged': 22200,\n",
       " 'disappointing': 21497,\n",
       " 'Chinese': 2792,\n",
       " 'factory': 23095,\n",
       " 'activity': 16515,\n",
       " 'data': 20763,\n",
       " 'brought': 18598,\n",
       " 'back': 17689,\n",
       " 'concern': 19897,\n",
       " 'health': 24764,\n",
       " 'economy': 22194,\n",
       " 'denting': 21130,\n",
       " 'risk': 32041,\n",
       " 'appetite': 17228,\n",
       " 'Spot': 13710,\n",
       " 'rose': 32128,\n",
       " 'per': 29592,\n",
       " 'ounce': 29104,\n",
       " 'European': 4579,\n",
       " 'equity': 22637,\n",
       " 'nudged': 28693,\n",
       " 'following': 23656,\n",
       " 'weaker': 36741,\n",
       " 'stock': 34055,\n",
       " 'BEIJING': 1243,\n",
       " 'tech': 34753,\n",
       " 'giant': 24187,\n",
       " 'Huawei': 6225,\n",
       " 'announced': 17064,\n",
       " 'plan': 29873,\n",
       " 'release': 31509,\n",
       " 'nextgeneration': 28442,\n",
       " 'smartphone': 33333,\n",
       " 'based': 17857,\n",
       " 'technology': 34772,\n",
       " 'instead': 25868,\n",
       " 'component': 19837,\n",
       " 'stepping': 34007,\n",
       " 'effort': 22235,\n",
       " 'compete': 19782,\n",
       " 'directly': 21463,\n",
       " 'Western': 15820,\n",
       " 'industry': 25666,\n",
       " 'leader': 26662,\n",
       " 'Thursdays': 14617,\n",
       " 'announcement': 17066,\n",
       " 'Technologies': 14381,\n",
       " 'Ltd': 8358,\n",
       " 'world': 37061,\n",
       " 'biggest': 18115,\n",
       " 'maker': 27273,\n",
       " 'network': 28390,\n",
       " 'gear': 24107,\n",
       " 'phone': 29734,\n",
       " 'company': 19750,\n",
       " 'combat': 19653,\n",
       " 'warning': 36676,\n",
       " 'might': 27706,\n",
       " 'security': 32602,\n",
       " 'Mumbai': 9538,\n",
       " 'India': 6545,\n",
       " 'Incs': 6530,\n",
       " 'external': 23010,\n",
       " 'commercial': 19702,\n",
       " 'borrowing': 18409,\n",
       " 'ECBs': 4200,\n",
       " 'billion': 18140,\n",
       " 'January': 7000,\n",
       " 'compared': 19756,\n",
       " 'yearago': 37167,\n",
       " 'period': 29627,\n",
       " 'Reserve': 12144,\n",
       " 'RBI': 11656,\n",
       " 'showed': 32986,\n",
       " 'Domestic': 4027,\n",
       " 'firm': 23450,\n",
       " 'raised': 31009,\n",
       " 'overseas': 29238,\n",
       " 'source': 33564,\n",
       " 'Of': 10295,\n",
       " 'total': 35283,\n",
       " 'month': 27998,\n",
       " 'automatic': 17604,\n",
       " 'route': 32151,\n",
       " 'remaining': 31553,\n",
       " 'million': 27734,\n",
       " 'taken': 34651,\n",
       " 'approval': 17270,\n",
       " 'according': 16429,\n",
       " 'ECB': 4199,\n",
       " 'On': 10349,\n",
       " 'Wednesday': 15786,\n",
       " 'Federal': 4854,\n",
       " 'Chairman': 2587,\n",
       " 'Jerome': 7077,\n",
       " 'Powell': 11266,\n",
       " 'said': 32258,\n",
       " 'interest': 25971,\n",
       " 'rate': 31072,\n",
       " 'could': 20328,\n",
       " 'hold': 25014,\n",
       " 'time': 35139,\n",
       " 'weigh': 36792,\n",
       " 'economic': 22188,\n",
       " 'outlook': 29137,\n",
       " 'inflation': 25714,\n",
       " 'remains': 31554,\n",
       " 'muted': 28205,\n",
       " 'year': 37162,\n",
       " 'gilt': 24199,\n",
       " 'yield': 37208,\n",
       " 'Wednesdays': 15787,\n",
       " 'Bond': 2015,\n",
       " 'opposite': 29004,\n",
       " 'direction': 21460,\n",
       " 'What': 15828,\n",
       " 'audience': 17535,\n",
       " 'I': 6302,\n",
       " 'done': 21839,\n",
       " 'Yeh': 16128,\n",
       " 'Hai': 5801,\n",
       " 'Aashiqui': 168,\n",
       " 'Pyaar': 11576,\n",
       " 'Tune': 14884,\n",
       " 'Kya': 7932,\n",
       " 'Kiya': 7735,\n",
       " 'always': 16928,\n",
       " 'thought': 35025,\n",
       " 'two': 35665,\n",
       " 'kind': 26426,\n",
       " 'people': 29584,\n",
       " '–': 37303,\n",
       " 'bad': 17737,\n",
       " 'keep': 26379,\n",
       " 'interchanging': 25966,\n",
       " 'situation': 33175,\n",
       " 'com': 19647,\n",
       " 'Arbaaz': 917,\n",
       " 'Khan': 7639,\n",
       " 'spoke': 33737,\n",
       " 'getting': 24173,\n",
       " 'Dabangg': 3514,\n",
       " 'Salman': 12647,\n",
       " 'perfectly': 29606,\n",
       " 'slipped': 33279,\n",
       " 'character': 19162,\n",
       " 'seven': 32802,\n",
       " 'shot': 32965,\n",
       " 'song': 33520,\n",
       " 'Indore': 6619,\n",
       " 'surprised': 34480,\n",
       " 'saw': 32371,\n",
       " 'brother': 18591,\n",
       " 'set': 32788,\n",
       " 'One': 10352,\n",
       " 'would': 37095,\n",
       " 'think': 34997,\n",
       " 'development': 21294,\n",
       " 'testing': 34907,\n",
       " 'process': 30545,\n",
       " 'uncovered': 35797,\n",
       " 'flaw': 23544,\n",
       " 'yet': 37203,\n",
       " 'proceeded': 30542,\n",
       " 'put': 30879,\n",
       " 'anyway': 17184,\n",
       " 'Bryan': 2177,\n",
       " 'Ma': 8520,\n",
       " 'vice': 36423,\n",
       " 'president': 30375,\n",
       " 'device': 21300,\n",
       " 'research': 31712,\n",
       " 'consultancy': 20080,\n",
       " 'IDC': 6331,\n",
       " 'Clearly': 2953,\n",
       " 'afford': 16683,\n",
       " 'another': 17091,\n",
       " 'embarrassing': 22344,\n",
       " 'Note': 10168,\n",
       " 'like': 26847,\n",
       " 'incident': 25534,\n",
       " 'lest': 26770,\n",
       " 'build': 18644,\n",
       " 'reputation': 31691,\n",
       " 'releasing': 31514,\n",
       " 'unreliable': 36054,\n",
       " 'product': 30573,\n",
       " 'episode': 22617,\n",
       " 'triggered': 35524,\n",
       " 'recall': 31200,\n",
       " 'cost': 20306,\n",
       " 'marred': 27390,\n",
       " 'battled': 17895,\n",
       " 'Apple': 870,\n",
       " 'Inc': 6512,\n",
       " 'premium': 30325,\n",
       " 'Pulling': 11521,\n",
       " 'Fold': 5007,\n",
       " 'address': 16557,\n",
       " 'potential': 30182,\n",
       " 'issue': 26171,\n",
       " 'race': 30968,\n",
       " 'flexible': 23559,\n",
       " 'gadget': 24015,\n",
       " 'ahead': 16757,\n",
       " 'rival': 32053,\n",
       " 'Co': 2989,\n",
       " 'Xiaomi': 16043,\n",
       " 'Corp': 3259,\n",
       " 'Samsung': 12687,\n",
       " 'spokeswoman': 33741,\n",
       " 'declined': 20913,\n",
       " 'comment': 19694,\n",
       " 'story': 34098,\n",
       " 'Shares': 13149,\n",
       " 'date': 20791,\n",
       " 'launch': 26617,\n",
       " 'little': 26937,\n",
       " 'changed': 19146,\n",
       " 'Seoul': 13023,\n",
       " 'bounced': 18436,\n",
       " 'since': 33123,\n",
       " '—': 37307,\n",
       " 'largest': 26575,\n",
       " 'producer': 30571,\n",
       " 'smartphones': 33343,\n",
       " 'memory': 27560,\n",
       " 'chip': 19270,\n",
       " 'counting': 20360,\n",
       " 'folding': 23648,\n",
       " 'extend': 23000,\n",
       " 'lead': 26661,\n",
       " 'mobile': 27893,\n",
       " 'kickstart': 26410,\n",
       " 'stagnating': 33846,\n",
       " 'Unveiled': 15136,\n",
       " 'along': 16898,\n",
       " 'thanniversary': 34933,\n",
       " 'version': 36396,\n",
       " 'flagship': 23513,\n",
       " 'Galaxy': 5268,\n",
       " 'S': 12421,\n",
       " 'underscored': 35857,\n",
       " 'ambition': 16954,\n",
       " 'make': 27270,\n",
       " 'Struggling': 13910,\n",
       " 'ward': 36657,\n",
       " 'hardcharging': 24658,\n",
       " 'Suwon': 14136,\n",
       " 'Koreabased': 7815,\n",
       " 'hoped': 25074,\n",
       " 'embody': 22355,\n",
       " 'cuttingedge': 20674,\n",
       " 'innovation': 25808,\n",
       " 'So': 13526,\n",
       " 'far': 23164,\n",
       " 'rupee': 32203,\n",
       " 'gained': 24022,\n",
       " 'foreign': 23707,\n",
       " 'bought': 18434,\n",
       " 'debt': 20863,\n",
       " 'Indias': 6588,\n",
       " 'benchmark': 18014,\n",
       " 'Sensex': 13016,\n",
       " 'point': 29993,\n",
       " 'preopen': 30332,\n",
       " 'trade': 35344,\n",
       " 'Year': 16116,\n",
       " 'however': 25137,\n",
       " 'see': 32612,\n",
       " 'presence': 30358,\n",
       " 'Jio': 7135,\n",
       " 'rural': 32209,\n",
       " 'enabler': 22421,\n",
       " 'eventually': 22748,\n",
       " 'expects': 22922,\n",
       " 'upgrade': 36146,\n",
       " 'Local': 8288,\n",
       " 'entrepreneur': 22590,\n",
       " 'apply': 17245,\n",
       " 'open': 28967,\n",
       " 'Mi': 9170,\n",
       " 'Stores': 13874,\n",
       " 'responsible': 31790,\n",
       " 'physical': 29781,\n",
       " 'infrastructure': 25743,\n",
       " 'real': 31123,\n",
       " 'estate': 22693,\n",
       " 'look': 27052,\n",
       " 'branding': 18485,\n",
       " 'store': 34083,\n",
       " 'detail': 21252,\n",
       " 'ad': 16534,\n",
       " 'read': 31110,\n",
       " 'No': 10112,\n",
       " 'whistle': 36887,\n",
       " 'Bezel': 1739,\n",
       " 'notch': 28632,\n",
       " 'lag': 26515,\n",
       " 'bloatware': 18266,\n",
       " 'tag': 34638,\n",
       " 'random': 31035,\n",
       " 'music': 28191,\n",
       " 'Just': 7244,\n",
       " 'better': 18064,\n",
       " 'contained': 20105,\n",
       " 'sketch': 33198,\n",
       " 'showing': 32990,\n",
       " 'triple': 35538,\n",
       " 'camera': 18803,\n",
       " 'setup': 32799,\n",
       " 'popup': 30102,\n",
       " 'front': 23912,\n",
       " 'facing': 23083,\n",
       " 'mechanism': 27494,\n",
       " 'seems': 32624,\n",
       " 'copper': 20254,\n",
       " 'heat': 24795,\n",
       " 'pipe': 29836,\n",
       " 'cooling': 20238,\n",
       " 'show': 32976,\n",
       " 'SIM': 12467,\n",
       " 'card': 18905,\n",
       " 'slot': 33289,\n",
       " 'moved': 28079,\n",
       " 'bottom': 18430,\n",
       " 'left': 26720,\n",
       " 'side': 33037,\n",
       " 'design': 21211,\n",
       " 'line': 26878,\n",
       " 'case': 18951,\n",
       " 'render': 31593,\n",
       " 'Wired': 15916,\n",
       " 'magazine': 27221,\n",
       " 'even': 22737,\n",
       " 'got': 24328,\n",
       " 'hand': 24598,\n",
       " 'productionready': 30576,\n",
       " 'prototype': 30735,\n",
       " 'OnePlus': 10355,\n",
       " 'Pro': 11412,\n",
       " 'posted': 30151,\n",
       " 'sample': 32310,\n",
       " 'Azerbaijan': 1209,\n",
       " 'Grand': 5600,\n",
       " 'Prix': 11402,\n",
       " 'held': 24828,\n",
       " 'Baku': 1407,\n",
       " 'Tuesday': 14869,\n",
       " 'healthy': 24768,\n",
       " 'faced': 23064,\n",
       " 'crosscurrent': 20520,\n",
       " 'conflicting': 19965,\n",
       " 'signal': 33066,\n",
       " 'official': 28835,\n",
       " 'decided': 20894,\n",
       " 'warranted': 36680,\n",
       " 'taking': 34657,\n",
       " 'patient': 29492,\n",
       " 'approach': 17263,\n",
       " 'interestrate': 25977,\n",
       " 'change': 19144,\n",
       " 'Public': 11507,\n",
       " 'bank': 17808,\n",
       " 'higher': 24911,\n",
       " 'removed': 31589,\n",
       " 'Allahabad': 561,\n",
       " 'Corporation': 3262,\n",
       " 'Dhanlaxmi': 3839,\n",
       " 'prompt': 30665,\n",
       " 'corrective': 20285,\n",
       " 'action': 16497,\n",
       " 'PCA': 10506,\n",
       " 'framework': 23837,\n",
       " 'subject': 34261,\n",
       " 'certain': 19101,\n",
       " 'condition': 19922,\n",
       " 'continuous': 20150,\n",
       " 'monitoring': 27981,\n",
       " 'feature': 23250,\n",
       " 'display': 21647,\n",
       " 'responsive': 31792,\n",
       " 'inturn': 26086,\n",
       " 'significantly': 33076,\n",
       " 'gaming': 24057,\n",
       " 'UI': 14953,\n",
       " 'experience': 22933,\n",
       " 'It': 6828,\n",
       " 'consume': 20085,\n",
       " 'battery': 17886,\n",
       " 'expect': 22917,\n",
       " 'toggle': 35205,\n",
       " 'switch': 34563,\n",
       " 'within': 36990,\n",
       " 'setting': 32791,\n",
       " 'much': 28094,\n",
       " 'present': 30360,\n",
       " 'Asus': 1075,\n",
       " 'ROG': 11699,\n",
       " 'Phone': 11025,\n",
       " 'Razer': 11994,\n",
       " 'TikTok': 14637,\n",
       " 'popular': 30088,\n",
       " 'child': 19258,\n",
       " 'criticism': 20498,\n",
       " 'different': 21376,\n",
       " 'quarter': 30908,\n",
       " 'circulation': 19357,\n",
       " 'pornographic': 30105,\n",
       " 'content': 20125,\n",
       " 'Any': 840,\n",
       " 'existing': 22893,\n",
       " 'installed': 25859,\n",
       " 'share': 32858,\n",
       " 'seeker': 32619,\n",
       " 'apps': 17278,\n",
       " 'ShareIt': 13142,\n",
       " 'New': 10012,\n",
       " 'Delhi': 3699,\n",
       " 'With': 15927,\n",
       " 'crore': 20513,\n",
       " 'using': 36249,\n",
       " 'option': 29033,\n",
       " 'others': 29097,\n",
       " 'blocking': 18277,\n",
       " 'access': 16397,\n",
       " 'Google': 5546,\n",
       " 'Play': 11126,\n",
       " 'Store': 13871,\n",
       " 'App': 865,\n",
       " 'may': 27464,\n",
       " 'desired': 21221,\n",
       " 'result': 31823,\n",
       " 'say': 32373,\n",
       " 'expert': 22943,\n",
       " 'blocked': 18275,\n",
       " 'download': 21898,\n",
       " 'short': 32941,\n",
       " 'videosharing': 36444,\n",
       " 'request': 31694,\n",
       " 'government': 24337,\n",
       " 'hive': 25000,\n",
       " 'rating': 31081,\n",
       " 'business': 18710,\n",
       " 'whollyowned': 36902,\n",
       " 'subsidiary': 34301,\n",
       " 'slump': 33307,\n",
       " 'sale': 32268,\n",
       " 'abide': 16325,\n",
       " 'rule': 32177,\n",
       " 'capital': 18868,\n",
       " 'regulator': 31438,\n",
       " 'Securities': 12945,\n",
       " 'Exchange': 4611,\n",
       " 'Board': 1977,\n",
       " 'Sebi': 12925,\n",
       " 'Crisil': 3335,\n",
       " 'press': 30381,\n",
       " 'Notwithstanding': 10180,\n",
       " 'rise': 32038,\n",
       " 'beginning': 17967,\n",
       " 'notched': 28633,\n",
       " 'reflecting': 31374,\n",
       " 'drag': 21929,\n",
       " 'overall': 29183,\n",
       " 'earnings': 22141,\n",
       " 'Even': 4590,\n",
       " 'hiveoff': 25002,\n",
       " 'likely': 26852,\n",
       " 'continue': 20145,\n",
       " 'driver': 21983,\n",
       " 'valuation': 36303,\n",
       " 'oneyear': 28935,\n",
       " 'forward': 23777,\n",
       " 'He': 5957,\n",
       " 'chooses': 19296,\n",
       " 'hide': 24895,\n",
       " 'CP': 2353,\n",
       " 'colleague': 19609,\n",
       " 'mother': 28039,\n",
       " 'house': 25123,\n",
       " 'form': 23739,\n",
       " 'sexual': 32828,\n",
       " 'relation': 31498,\n",
       " 'first': 23458,\n",
       " 'three': 35041,\n",
       " 'Oh': 10313,\n",
       " 'right': 32015,\n",
       " 'dare': 20742,\n",
       " 'find': 23419,\n",
       " 'happiness': 24643,\n",
       " '”': 37348,\n",
       " 'offer': 28810,\n",
       " 'explanation': 22956,\n",
       " 'Phil': 11007,\n",
       " 'soldier': 33482,\n",
       " 'People': 10938,\n",
       " 'Special': 13660,\n",
       " 'packed': 29305,\n",
       " 'pop': 30085,\n",
       " 'culture': 20596,\n",
       " 'reference': 31357,\n",
       " 'Gone': 5535,\n",
       " 'Girl': 5461,\n",
       " 'Mindy': 9245,\n",
       " 'Kaling': 7365,\n",
       " 'That': 14516,\n",
       " 'opera': 28976,\n",
       " 'simply': 33112,\n",
       " 'go': 24273,\n",
       " 'trying': 35590,\n",
       " 'aim': 16764,\n",
       " 'new': 28411,\n",
       " 'iPad': 25255,\n",
       " 'specific': 33637,\n",
       " 'type': 35704,\n",
       " 'audience—artists': 17539,\n",
       " 'aware': 17662,\n",
       " 'fact': 23084,\n",
       " 'slumping': 33309,\n",
       " 'ship': 32910,\n",
       " 'sailing': 32261,\n",
       " 'promoting': 30662,\n",
       " 'highend': 24909,\n",
       " 'ideal': 25298,\n",
       " 'artist': 17374,\n",
       " 'photographer': 29767,\n",
       " 'creator': 20441,\n",
       " 'perfect': 29603,\n",
       " 'eagerly': 22119,\n",
       " 'waiting': 36620,\n",
       " 'refresh': 31388,\n",
       " 'last': 26582,\n",
       " 'update': 36129,\n",
       " 'came': 18800,\n",
       " 'nearly': 28321,\n",
       " 'ago': 16736,\n",
       " 'anticipate': 17129,\n",
       " 'though': 35024,\n",
       " 'drastically': 21947,\n",
       " 'increased': 25575,\n",
       " 'iPhones': 25267,\n",
       " 'loved': 27097,\n",
       " 'iPhone': 25260,\n",
       " 'stagnated': 33845,\n",
       " 'high': 24898,\n",
       " 'managed': 27295,\n",
       " 'increase': 25574,\n",
       " 'revenue': 31907,\n",
       " 'For': 5020,\n",
       " 'Plus': 11149,\n",
       " 'priced': 30441,\n",
       " '₹': 37358,\n",
       " 'XS': 16022,\n",
       " 'start': 33906,\n",
       " 'Facebook': 4755,\n",
       " 'eligible': 22316,\n",
       " 'able': 16328,\n",
       " 'money': 27969,\n",
       " 'video': 36435,\n",
       " 'Ad': 272,\n",
       " 'Breaks': 2102,\n",
       " 'Photo': 11031,\n",
       " 'AFP': 25,\n",
       " 'launching': 26631,\n",
       " 'Watch': 15736,\n",
       " 'YouTube': 16172,\n",
       " 'internationally': 26005,\n",
       " 'expanding': 22909,\n",
       " 'financial': 23412,\n",
       " 'incentive': 25519,\n",
       " 'encourage': 22442,\n",
       " 'FacebookFacebook': 4758,\n",
       " 'WatchFacebook': 15739,\n",
       " 'serviceYouTubeFidji': 32779,\n",
       " 'Simoentertainmentsports': 13371,\n",
       " 'contenttechnology': 20128,\n",
       " 'Starring': 13800,\n",
       " 'Varun': 15319,\n",
       " 'Dhawan': 3858,\n",
       " 'Alia': 539,\n",
       " 'Bhatt': 1802,\n",
       " 'Sonakshi': 13577,\n",
       " 'Sinha': 13408,\n",
       " 'Aditya': 305,\n",
       " 'Roy': 12370,\n",
       " 'Kapur': 7442,\n",
       " 'Madhuri': 8579,\n",
       " 'Dixit': 3999,\n",
       " 'Sanjay': 12728,\n",
       " 'Dutt': 4176,\n",
       " 'Kalank': 7348,\n",
       " 'opening': 28970,\n",
       " 'released': 31513,\n",
       " 'wanted': 36650,\n",
       " 'extended': 23001,\n",
       " 'weekend': 36786,\n",
       " 'competition': 19789,\n",
       " 'sight': 33060,\n",
       " 'film': 23371,\n",
       " 'splendid': 33722,\n",
       " 'box': 18456,\n",
       " 'office': 28830,\n",
       " 'tweeted': 35648,\n",
       " 'bang…': 17803,\n",
       " 'Emerges': 4416,\n",
       " 'opener': 28969,\n",
       " 'far…': 23186,\n",
       " 'Plexes': 11144,\n",
       " 'terrific…': 34883,\n",
       " 'Impressive': 6494,\n",
       " 'cast': 18973,\n",
       " 'hype': 25221,\n",
       " 'massive': 27416,\n",
       " 'screen': 32472,\n",
       " 'count': 20334,\n",
       " 'MahavirJayanti': 8640,\n",
       " 'holiday': 25022,\n",
       " 'contributed': 20172,\n",
       " 'big': 18111,\n",
       " 'total…': 35291,\n",
       " 'Wed': 15783,\n",
       " 'GKN': 5190,\n",
       " 'barred': 17848,\n",
       " 'misuse': 27869,\n",
       " 'socalled': 33446,\n",
       " 'dark': 20746,\n",
       " 'fibre': 23331,\n",
       " 'appealed': 17218,\n",
       " 'SEBI': 12451,\n",
       " 'separate': 32748,\n",
       " 'order': 29055,\n",
       " 'NSE': 9721,\n",
       " 'six': 33178,\n",
       " 'disgorge': 21592,\n",
       " 'profit': 30596,\n",
       " 'colocation': 19627,\n",
       " 'service': 32778,\n",
       " 'including': 25547,\n",
       " 'Fintech': 4936,\n",
       " 'startup': 33914,\n",
       " 'Zeta': 16255,\n",
       " 'cofounded': 19569,\n",
       " 'Bhavin': 1810,\n",
       " 'Turakhia': 14890,\n",
       " 'Ramki': 11891,\n",
       " 'Gaddipati': 5242,\n",
       " 'digitise': 21414,\n",
       " 'employee': 22405,\n",
       " 'benefit': 18025,\n",
       " 'cafeteria': 18768,\n",
       " 'solution': 33498,\n",
       " 'reward': 31975,\n",
       " 'recognition': 31249,\n",
       " 'offering': 28818,\n",
       " 'cloudbased': 19492,\n",
       " 'enterprise': 22560,\n",
       " 'suite': 34370,\n",
       " 'called': 18786,\n",
       " 'tax': 34717,\n",
       " 'package': 29302,\n",
       " 'includes': 25546,\n",
       " 'payment': 29521,\n",
       " 'published': 30795,\n",
       " 'wire': 36964,\n",
       " 'agency': 16712,\n",
       " 'feed': 23278,\n",
       " 'modification': 27935,\n",
       " 'text': 34910,\n",
       " 'Only': 10365,\n",
       " 'headline': 24741,\n",
       " 'Globally': 5483,\n",
       " 'established': 22689,\n",
       " 'Stratasys': 13885,\n",
       " 'Optomec': 10400,\n",
       " 'footprint': 23681,\n",
       " 'partnership': 29449,\n",
       " 'note': 28637,\n",
       " 'abovecited': 16340,\n",
       " 'Wresearch': 15978,\n",
       " 'Major': 8685,\n",
       " 'active': 16509,\n",
       " 'Indian': 6578,\n",
       " 'Dprinting': 4077,\n",
       " 'space': 33577,\n",
       " 'Altem': 592,\n",
       " 'Imaginarium': 6473,\n",
       " 'Brahma': 2075,\n",
       " 'KCbots': 7261,\n",
       " 'JGroup': 6863,\n",
       " 'Robotics': 12287,\n",
       " 'sit': 33166,\n",
       " 'Disney': 3967,\n",
       " 'Research': 12139,\n",
       " 'Magic': 8600,\n",
       " 'Bench': 1668,\n",
       " 'elephant': 22304,\n",
       " 'glowing': 24265,\n",
       " 'orb': 29047,\n",
       " 'Or': 10401,\n",
       " 'tiny': 35171,\n",
       " 'donkey': 21840,\n",
       " 'saunter': 32363,\n",
       " 'kick': 26404,\n",
       " 'bench': 18013,\n",
       " 'Similarly': 13367,\n",
       " 'scientist': 32434,\n",
       " 'Worcester': 15952,\n",
       " 'Polytechnic': 11203,\n",
       " 'Institute': 6699,\n",
       " 'Microsoft': 9191,\n",
       " 'HoloLens': 6142,\n",
       " 'explore': 22971,\n",
       " 'complex': 19820,\n",
       " 'biological': 18161,\n",
       " 'D': 3421,\n",
       " 'creating': 20435,\n",
       " 'tool': 35239,\n",
       " 'critical': 20491,\n",
       " 'link': 26894,\n",
       " 'protein': 30726,\n",
       " 'gene': 24119,\n",
       " 'related': 31495,\n",
       " 'disorder': 21629,\n",
       " 'cancer': 18836,\n",
       " 'diabetes': 21329,\n",
       " 'Both': 2050,\n",
       " 'example': 22806,\n",
       " 'highlight': 24926,\n",
       " 'melding': 27538,\n",
       " 'augmented': 17554,\n",
       " 'reality': 31135,\n",
       " 'AR': 107,\n",
       " 'virtual': 36498,\n",
       " 'VR': 15227,\n",
       " 'mixed': 27877,\n",
       " 'MR': 8488,\n",
       " 'blended': 18246,\n",
       " 'concept': 19890,\n",
       " 'While': 15847,\n",
       " 'created': 20433,\n",
       " 'solely': 33485,\n",
       " 'computer': 19871,\n",
       " 'online': 28941,\n",
       " 'still': 34035,\n",
       " 'element': 22301,\n",
       " 'built': 18649,\n",
       " 'atop': 17489,\n",
       " 'akin': 16797,\n",
       " 'layer': 26654,\n",
       " 'information': 25734,\n",
       " 'mix': 27876,\n",
       " 'bid': 18105,\n",
       " 'capture': 18895,\n",
       " 'best': 18043,\n",
       " 'traction': 35342,\n",
       " 'need': 28340,\n",
       " 'headset': 24753,\n",
       " 'Regardless': 12067,\n",
       " 'believe': 17995,\n",
       " 'become': 17938,\n",
       " 'next': 28439,\n",
       " 'computing': 19874,\n",
       " 'platform': 29900,\n",
       " 'Consider': 3192,\n",
       " 'one': 28897,\n",
       " 'seen': 32625,\n",
       " 'Leap': 8134,\n",
       " 'goggles': 24290,\n",
       " 'ever': 22751,\n",
       " 'Yet': 16138,\n",
       " 'raise': 31008,\n",
       " 'investment': 26116,\n",
       " 'almost': 16895,\n",
       " 'notably': 28631,\n",
       " 'Alibaba': 541,\n",
       " 'Group': 5647,\n",
       " 'Temasek': 14426,\n",
       " 'JP': 6872,\n",
       " 'Morgan': 9432,\n",
       " 'Investment': 6765,\n",
       " 'Management': 8747,\n",
       " 'finally': 23409,\n",
       " 'Creator': 3320,\n",
       " 'Edition': 4319,\n",
       " 'available': 17626,\n",
       " 'Other': 10452,\n",
       " 'player': 29912,\n",
       " 'include': 25543,\n",
       " 'Intel': 6709,\n",
       " 'Seiko': 12965,\n",
       " 'Epson': 4512,\n",
       " 'Accenture': 214,\n",
       " 'PLC': 10556,\n",
       " 'Sony': 13595,\n",
       " 'Electronics': 4378,\n",
       " 'HTC': 5783,\n",
       " 'Imaginate': 6474,\n",
       " 'increasingly': 25577,\n",
       " 'betting': 18073,\n",
       " 'Gartner': 5327,\n",
       " 'predicts': 30281,\n",
       " 'evaluated': 22729,\n",
       " 'adopted': 16602,\n",
       " 'largeenterprise': 26567,\n",
       " 'size': 33188,\n",
       " 'expected': 22919,\n",
       " 'reach': 31100,\n",
       " 'Reportbuyercom': 12121,\n",
       " 'belief': 17993,\n",
       " 'rapid': 31055,\n",
       " 'increasing': 25576,\n",
       " 'demand': 21070,\n",
       " 'innovative': 25810,\n",
       " 'wearable': 36754,\n",
       " 'aerospace': 16659,\n",
       " 'defence': 20973,\n",
       " 'use': 36221,\n",
       " 'training': 35372,\n",
       " 'programme': 30609,\n",
       " 'used': 36225,\n",
       " 'effectively': 22226,\n",
       " 'school': 32429,\n",
       " 'provides': 30752,\n",
       " 'leading': 26670,\n",
       " 'interactive': 25957,\n",
       " 'learning': 26696,\n",
       " 'report': 31656,\n",
       " 'mintindiawire': 27798,\n",
       " 'longreads': 27044,\n",
       " 'TechnologyFuture': 14384,\n",
       " 'TechnologyArtificial': 14383,\n",
       " 'IntelligenceBlockchainInternet': 6712,\n",
       " 'ThingsD': 14555,\n",
       " 'printingMixed': 30482,\n",
       " 'RealityAugmented': 12005,\n",
       " 'RealityVirtual': 12006,\n",
       " ...}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9d529c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tamilrockers successfully evaded authority also acquired audience'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['STORY'][3570]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7b0e501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 14309)\t1\n",
      "  (0, 16485)\t1\n",
      "  (0, 16909)\t1\n",
      "  (0, 17535)\t1\n",
      "  (0, 17583)\t1\n",
      "  (0, 22727)\t1\n",
      "  (0, 34330)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 37366)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#THIS IS CREATING THE 37366 COLUMN TO A SINGL DOC \n",
    "bow0 = bow_transformer.transform([df['STORY'][3570]])\n",
    "print(bow0)#THIS IS TELLING THE WHICH XOLUMN HAVE THE VALUE AND HOW MUCH TIME IT APPER IN THE WHOLE CORPUS\n",
    "bow0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a668b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW TRANSFORMING THE WHOLE TEXT DOCUMNET INTO THE VECTOR FORM\n",
    "bag_cor=bow_transformer.transform(df['STORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "292125a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (7628, 37366)\n",
      "Amount of Non-Zero occurences:  414817\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Sparse Matrix: ', bag_cor.shape)\n",
    "print('Amount of Non-Zero occurences: ', bag_cor.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c140d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6fb08eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizing the Bag of Words with TFIDF technique\n",
    "#TF -IDF transsformer\n",
    "#we use tfidf transformer becuase it perfrom extra step NOrmalization\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer().fit(bag_cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0130d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfTransformer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c77436fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 34330)\t0.40184682314878395\n",
      "  (0, 22727)\t0.538883326811997\n",
      "  (0, 17583)\t0.3478936262784853\n",
      "  (0, 17535)\t0.2864912199194279\n",
      "  (0, 16909)\t0.13703726826382162\n",
      "  (0, 16485)\t0.38106005714334484\n",
      "  (0, 14309)\t0.42547704576139966\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_transformer.transform(bow0))#this is only transforming one doc into using the tfidf will return the tfidf frequency in the whole corpus\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a2c4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now transforming the whole BAg of words corpus into the tfidf transforme\n",
    "story_tfidf = tfidf_transformer.transform(bag_cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12ab5a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7628, 37366)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be315fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 37346)\t0.028530891763480833\n",
      "  (0, 36991)\t0.06117086811537767\n",
      "  (0, 36807)\t0.05741616748655896\n",
      "  (0, 36733)\t0.05923092601715939\n",
      "  (0, 36591)\t0.12758256213306418\n",
      "  (0, 36145)\t0.23916786821818137\n",
      "  (0, 35938)\t0.14478489230365854\n",
      "  (0, 35772)\t0.09347058761651476\n",
      "  (0, 35629)\t0.08589113433716208\n",
      "  (0, 35238)\t0.07347921453764354\n",
      "  (0, 35118)\t0.10346191058259437\n",
      "  (0, 34479)\t0.08803410767931644\n",
      "  (0, 34204)\t0.12516883445337026\n",
      "  (0, 34190)\t0.07132666136300277\n",
      "  (0, 33828)\t0.09126932229702363\n",
      "  (0, 32902)\t0.08702354830292684\n",
      "  (0, 32890)\t0.10346191058259437\n",
      "  (0, 32587)\t0.0774969844970997\n",
      "  (0, 32247)\t0.11672910019767622\n",
      "  (0, 32230)\t0.10953363466759936\n",
      "  (0, 31917)\t0.12307796843288264\n",
      "  (0, 31079)\t0.08824428849562609\n",
      "  (0, 30651)\t0.14953383612846916\n",
      "  (0, 30504)\t0.07954226610195567\n",
      "  (0, 30213)\t0.09317790179187543\n",
      "  :\t:\n",
      "  (0, 23289)\t0.07432581183251401\n",
      "  (0, 23276)\t0.3855384839092526\n",
      "  (0, 20961)\t0.13043739604447865\n",
      "  (0, 20832)\t0.14222530050836235\n",
      "  (0, 20404)\t0.10873047217370274\n",
      "  (0, 20027)\t0.09568858480122469\n",
      "  (0, 19663)\t0.051087007543080445\n",
      "  (0, 19414)\t0.09347058761651476\n",
      "  (0, 18408)\t0.11958393410909068\n",
      "  (0, 18369)\t0.11127523187922325\n",
      "  (0, 18367)\t0.08416871439151237\n",
      "  (0, 17768)\t0.08911441432341446\n",
      "  (0, 16979)\t0.14478489230365854\n",
      "  (0, 16971)\t0.06304333030105823\n",
      "  (0, 16437)\t0.10403136372726339\n",
      "  (0, 16436)\t0.10346191058259437\n",
      "  (0, 16135)\t0.09469931466769406\n",
      "  (0, 14573)\t0.04859459509624692\n",
      "  (0, 7437)\t0.08956830800844734\n",
      "  (0, 6768)\t0.09438297591452285\n",
      "  (0, 5443)\t0.25033766890674053\n",
      "  (0, 4544)\t0.1384360240684521\n",
      "  (0, 2243)\t0.11158012125264759\n",
      "  (0, 1482)\t0.0744130445690531\n",
      "  (0, 993)\t0.06483479454753888\n"
     ]
    }
   ],
   "source": [
    "print(story_tfidf[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1f92e2",
   "metadata": {},
   "source": [
    "# Training a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16d49576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>length_text</th>\n",
       "      <th>word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>The movie follows event Miss World competition...</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6638</th>\n",
       "      <td>This feature added Android version instant mes...</td>\n",
       "      <td>1</td>\n",
       "      <td>313</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>“ BankChain launched India February explore bu...</td>\n",
       "      <td>1</td>\n",
       "      <td>735</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>It could explained away bringing different rea...</td>\n",
       "      <td>2</td>\n",
       "      <td>414</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>S rocking chart Hollywood Indian show audience...</td>\n",
       "      <td>2</td>\n",
       "      <td>506</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  STORY  SECTION  length_text  \\\n",
       "7086  The movie follows event Miss World competition...        2           82   \n",
       "6638  This feature added Android version instant mes...        1          313   \n",
       "1090  “ BankChain launched India February explore bu...        1          735   \n",
       "6490  It could explained away bringing different rea...        2          414   \n",
       "1699  S rocking chart Hollywood Indian show audience...        2          506   \n",
       "\n",
       "      word_length  \n",
       "7086           12  \n",
       "6638           35  \n",
       "1090          102  \n",
       "6490           53  \n",
       "1699           75  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf6f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a00346cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Assuming story_tfidf is your TF-IDF matrix and custom_feature is your custom feature matrix\n",
    "custom_feature = df.iloc[:, 2:]\n",
    "\n",
    "# Convert custom_feature to a sparse matrix\n",
    "custom_feature_sparse = csr_matrix(custom_feature)\n",
    "\n",
    "#combing the custom feature and tfidf feature\n",
    "\n",
    "combined_feature=hstack([story_tfidf,custom_feature_sparse])\n",
    "\n",
    "y=df['SECTION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_feature, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "22241bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5339, 37368)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a4380c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the ML model using the navive Bayes classifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "news_category_Detect_model = MultinomialNB()\n",
    "\n",
    "news_category_Detect_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e028732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = news_category_Detect_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8df648ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d7e66ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48405417212756663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.50      0.65       491\n",
      "           1       0.42      1.00      0.59       846\n",
      "           2       1.00      0.01      0.01       598\n",
      "           3       1.00      0.04      0.08       354\n",
      "\n",
      "    accuracy                           0.48      2289\n",
      "   macro avg       0.84      0.39      0.33      2289\n",
      "weighted avg       0.77      0.48      0.37      2289\n",
      "\n",
      "[[245 246   0   0]\n",
      " [  1 845   0   0]\n",
      " [ 16 579   3   0]\n",
      " [  1 338   0  15]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test,prediction))\n",
    "\n",
    "print(classification_report(y_test,prediction))\n",
    "\n",
    "print(confusion_matrix(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b697db",
   "metadata": {},
   "source": [
    "Accuracy score of using the NAive bayse is about 48% which is very low so we using some othe rclassification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97ef92f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random forest classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17ef9c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.944517256443862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       491\n",
      "           1       0.94      0.96      0.95       846\n",
      "           2       0.93      0.97      0.95       598\n",
      "           3       0.97      0.90      0.93       354\n",
      "\n",
      "    accuracy                           0.94      2289\n",
      "   macro avg       0.95      0.94      0.94      2289\n",
      "weighted avg       0.95      0.94      0.94      2289\n",
      "\n",
      "[[452  24  12   3]\n",
      " [  5 810  23   8]\n",
      " [  8   8 582   0]\n",
      " [  5  19  12 318]]\n"
     ]
    }
   ],
   "source": [
    "predict = rfc.predict(X_test)\n",
    "\n",
    "#score of Random Forest Classifier model\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test,predict))\n",
    "\n",
    "print(classification_report(y_test,predict))\n",
    "\n",
    "print(confusion_matrix(y_test,predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749f10e5",
   "metadata": {},
   "source": [
    "By using the random foreset classification its accuracy score is about 94% which is good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27659ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the support vector machine\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model=SVC()\n",
    "svm_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "621187d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4635211882918305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.02      0.04       491\n",
      "           1       0.42      0.84      0.56       846\n",
      "           2       0.59      0.57      0.58       598\n",
      "           3       0.00      0.00      0.00       354\n",
      "\n",
      "    accuracy                           0.46      2289\n",
      "   macro avg       0.36      0.36      0.29      2289\n",
      "weighted avg       0.40      0.46      0.37      2289\n",
      "\n",
      "[[  9 435  47   0]\n",
      " [ 11 713 122   0]\n",
      " [  1 258 339   0]\n",
      " [  0 283  71   0]]\n",
      "this is also not produce good result its accuracy is about only 46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predict = svm_model.predict(X_test)\n",
    "\n",
    "#score of suppport vector  Classifier model\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test,predict))\n",
    "\n",
    "print(classification_report(y_test,predict))\n",
    "\n",
    "print(confusion_matrix(y_test,predict))\n",
    "print('this is also not produce good result its accuracy is about only 46%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "306d6510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training one more model which is xgboost\n",
    "#THIS IS ALSO A ENSEMBLE ALGORITHM\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f55ad286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947138488422892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       491\n",
      "           1       0.95      0.95      0.95       846\n",
      "           2       0.94      0.97      0.95       598\n",
      "           3       0.92      0.93      0.93       354\n",
      "\n",
      "    accuracy                           0.95      2289\n",
      "   macro avg       0.95      0.94      0.94      2289\n",
      "weighted avg       0.95      0.95      0.95      2289\n",
      "\n",
      "[[456  20   8   7]\n",
      " [  3 804  19  20]\n",
      " [  7  11 579   1]\n",
      " [  3  13   9 329]]\n"
     ]
    }
   ],
   "source": [
    "predict = xgb_model.predict(X_test)\n",
    "\n",
    "#score of suppport vector  Classifier model\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test,predict))\n",
    "\n",
    "print(classification_report(y_test,predict))\n",
    "\n",
    "print(confusion_matrix(y_test,predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc492a7",
   "metadata": {},
   "source": [
    "This model has slitly better result than Random forest classifier whixh is ABOUT 95%\n",
    "\n",
    "<b>So i am using the XGB boost modelfor my news category classification problem</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9bb8117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now predictiong another test file data for submission\n",
    "test_data =pd.read_excel('Participants_Data_News_category/Data_Test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d99ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = xgb_model.predict(test_data)\n",
    "tst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1775557",
   "metadata": {},
   "source": [
    "# creating a pipeline for my news Category classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9eb2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3dd0bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_create_custom_feature(df):\n",
    "    \n",
    "    #length of text\n",
    "    df['length_text'] = df['STORY'].apply(len)\n",
    "    \n",
    "    df['word_length'] = df['STORY'].apply(lambda row:len(row.split(' ')) if not pd.isnull(row) else 0)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8137208c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "025daafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_feature = df.iloc[:, 2:]\n",
    "\n",
    "# Convert custom_feature to a sparse matrix\n",
    "custom_feature_sparse = csr_matrix(custom_feature)\n",
    "\n",
    "#combing the custom feature and tfidf feature\n",
    "\n",
    "combined_feature=hstack([story_tfidf,custom_feature_sparse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaaa6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5fedb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d16d833e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#i have to add the following task into the pipeline\n",
    "\n",
    "#text preprocessing\n",
    "#text vectorizer \n",
    "#model training\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('wordnet')\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "#TEXT PREPROCESSING FUNCTION\n",
    "def text_pre_process(text):\n",
    "    \n",
    "    #removing the punctuation\n",
    "    text=[char for char in text if char not in string.punctuation]\n",
    "    text=''.join(text)\n",
    "    \n",
    "    #removing the number\n",
    "    text =re.sub('[0-9]','',text)\n",
    "    \n",
    "    #removing the stopwords\n",
    "    no_stop=[word for word in text.split() if word not in stopwords.words('english')]\n",
    "    \n",
    "    no_stop=' '.join(no_stop)\n",
    "    \n",
    "    #removing the emoji in the text\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\" # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    rem_emooji_text = emoji_pattern.sub(r'', no_stop)\n",
    "\n",
    "    \n",
    "    #doing the lemaatization\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    \n",
    "    #it will split the sentence into the words\n",
    "    word_tokens = word_tokenize(rem_emooji_text)\n",
    "    fin_txt =[lemmatizer.lemmatize(word) for word in word_tokens] \n",
    "    \n",
    "    \n",
    "    return fin_txt\n",
    "\n",
    "\n",
    "#function to add more feature\n",
    "\n",
    "def add_create_custom_feature(df):\n",
    "    \n",
    "    #length of text\n",
    "    df['length_text'] = df['STORY'].apply(len)\n",
    "    \n",
    "    df['word_length'] = df['STORY'].apply(lambda row:len(row.split(' ')) if not pd.isnull(row) else 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "custom_feature = df.iloc[:, 2:]\n",
    "\n",
    "def combine_features(tfidf_feature, custom_feature):\n",
    "    # Convert custom_feature to a sparse matrix\n",
    "    custom_feature_sparse = csr_matrix(custom_feature)\n",
    "\n",
    "    # Combine the TF-IDF feature and the custom feature\n",
    "    combined_feature = hstack([tfidf_feature, custom_feature_sparse])\n",
    "\n",
    "    return combined_feature\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_pre_process)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('custom_featureAdd',FunctionTransformer(add_create_custom_feature)),\n",
    "    ('combined_features', FunctionTransformer(combine_features)),\n",
    "    ('classifier_model',XGBClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcf243c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "056eecc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#i have to add the following task \n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('wordnet')\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "#TEXT PREPROCESSING FUNCTION\n",
    "def text_pre_process(text):\n",
    "    \n",
    "    #removing the punctuation\n",
    "    text=[char for char in text if char not in string.punctuation]\n",
    "    text=''.join(text)\n",
    "    \n",
    "    #removing the number\n",
    "    text =re.sub('[0-9]','',text)\n",
    "    \n",
    "    \n",
    "    df['length_text'] = len(text)\n",
    "    df['word_length'] = len(text.split(' '))\n",
    "    \n",
    "    \n",
    "    #removing the stopwords\n",
    "    no_stop=[word for word in text.split() if word not in stopwords.words('english')]\n",
    "    \n",
    "    no_stop=' '.join(no_stop)\n",
    "    \n",
    "    #removing the emoji in the text\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\" # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    rem_emooji_text = emoji_pattern.sub(r'', no_stop)\n",
    "\n",
    "    \n",
    "    #doing the lemaatization\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    \n",
    "    #it will split the sentence into the words\n",
    "    word_tokens = word_tokenize(rem_emooji_text)\n",
    "    fin_txt =[lemmatizer.lemmatize(word) for word in word_tokens] \n",
    "    \n",
    "    \n",
    "    return fin_txt\n",
    "\n",
    "\n",
    "#function to add more feature\n",
    "\n",
    "# def add_create_custom_feature(df):\n",
    "    \n",
    "#     #length of text\n",
    "#     df['length_text'] = df['STORY'].apply(len)\n",
    "    \n",
    "#     df['word_length'] = df['STORY'].apply(lambda row:len(row.split(' ')) if not pd.isnull(row) else 0)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "\n",
    "custom_feature = df.iloc[:, 2:]\n",
    "\n",
    "def combine_features(features):\n",
    "    combined_feature = hstack(features)\n",
    "    return combined_feature\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_pre_process)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    #('custom_featureAdd',FunctionTransformer(add_create_custom_feature)),\n",
    "    ('combined_features', FunctionTransformer(combine_features, validate=False)),\n",
    "    ('classifier_model',XGBClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1cc229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b228a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b35345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "359bd472",
   "metadata": {},
   "outputs": [],
   "source": [
    "PX_train, PX_test, Py_train, Py_test = train_test_split(df['STORY'], df['SECTION'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2cb96fcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "blocks must be 2-D",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mPy_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 401\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    357\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\base.py:881\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:238\u001b[0m, in \u001b[0;36mFunctionTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform X using the forward function.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03m    Transformed input.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:310\u001b[0m, in \u001b[0;36mFunctionTransformer._transform\u001b[1;34m(self, X, func, kw_args)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    308\u001b[0m     func \u001b[38;5;241m=\u001b[39m _identity\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkw_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkw_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[72], line 76\u001b[0m, in \u001b[0;36mcombine_features\u001b[1;34m(features)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_features\u001b[39m(features):\n\u001b[1;32m---> 76\u001b[0m     combined_feature \u001b[38;5;241m=\u001b[39m \u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_feature\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\scipy\\sparse\\_construct.py:535\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhstack\u001b[39m(blocks, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    506\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03m    Stack sparse matrices horizontally (column wise)\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    533\u001b[0m \n\u001b[0;32m    534\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\scipy\\sparse\\_construct.py:618\u001b[0m, in \u001b[0;36mbmat\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    615\u001b[0m blocks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(blocks, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blocks\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 618\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblocks must be 2-D\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    620\u001b[0m M,N \u001b[38;5;241m=\u001b[39m blocks\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    622\u001b[0m \u001b[38;5;66;03m# check for fast path cases\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: blocks must be 2-D"
     ]
    }
   ],
   "source": [
    "pipe.fit(PX_train,Py_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f639b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a0dc81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c341b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12cc721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5032c19",
   "metadata": {},
   "source": [
    "# Using Column Transformer to create the data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093497a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose impo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fae0f7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 5339, expected 3.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Step 6: Fit the pipeline on training data\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Step 7: Make predictions on test data\u001b[39;00m\n\u001b[0;32m     78\u001b[0m predict \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 401\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    357\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\pipeline.py:1200\u001b[0m, in \u001b[0;36mFeatureUnion.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1197\u001b[0m Xs, transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults)\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_transformer_list(transformers)\n\u001b[1;32m-> 1200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\pipeline.py:1259\u001b[0m, in \u001b[0;36mFeatureUnion._hstack\u001b[1;34m(self, Xs)\u001b[0m\n\u001b[0;32m   1256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat(Xs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(sparse\u001b[38;5;241m.\u001b[39missparse(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m Xs):\n\u001b[1;32m-> 1259\u001b[0m     Xs \u001b[38;5;241m=\u001b[39m \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtocsr()\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1261\u001b[0m     Xs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack(Xs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\scipy\\sparse\\_construct.py:535\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhstack\u001b[39m(blocks, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    506\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03m    Stack sparse matrices horizontally (column wise)\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    533\u001b[0m \n\u001b[0;32m    534\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\scipy\\sparse\\_construct.py:668\u001b[0m, in \u001b[0;36mbmat\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m brow_lengths[i] \u001b[38;5;241m!=\u001b[39m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    665\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblocks[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,:] has incompatible row dimensions. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    666\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGot blocks[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m].shape[0] == \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    667\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbrow_lengths[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 668\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bcol_lengths[j] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    671\u001b[0m     bcol_lengths[j] \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 5339, expected 3."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "# Step 1: Load the data\n",
    "df = pd.read_excel('Participants_Data_News_category/Data_Train.xlsx')\n",
    "\n",
    "# Step 2: Preprocessing functions\n",
    "nltk.download('wordnet')\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def pre_process(text):\n",
    "    text = [char for char in text if char not in string.punctuation]\n",
    "    text = ''.join(text)\n",
    "    text = re.sub('[0-9]', '', text)\n",
    "    no_stop = [word for word in text.split() if word not in stopwords.words('english')]\n",
    "    no_stop = ' '.join(no_stop)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_tokens = word_tokenize(no_stop)\n",
    "    fin_txt = ' '.join([lemmatizer.lemmatize(word) for word in word_tokens])\n",
    "    return fin_txt\n",
    "\n",
    "# Step 3: Custom Feature Transformer\n",
    "class CustomFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        X_transformed['word_length'] = X_transformed['STORY'].apply(lambda x: len(x.split()))\n",
    "        X_transformed['text_length'] = X_transformed['STORY'].apply(len)\n",
    "        return X_transformed[['STORY', 'word_length', 'text_length']]\n",
    "\n",
    "# Step 4: Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('custom_features', CustomFeatureTransformer()),\n",
    "    ('features', FeatureUnion([\n",
    "        ('text_pipeline', Pipeline([\n",
    "            ('preprocess', CountVectorizer(analyzer=pre_process)),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        ('numeric_features', FunctionTransformer(lambda X: X[['word_length', 'text_length']], validate=False))\n",
    "    ])),\n",
    "    ('classifier', xgb.XGBClassifier())\n",
    "])\n",
    "\n",
    "# Step 5: Split the data into train and test sets\n",
    "X = df[['STORY', 'SECTION']]\n",
    "y = df['SECTION']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 6: Fit the pipeline on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Make predictions on test data\n",
    "predict = pipeline.predict(X_test)\n",
    "\n",
    "# Step 8: Evaluate the model's performance\n",
    "print(accuracy_score(y_test, predict))\n",
    "print(classification_report(y_test, predict))\n",
    "print(confusion_matrix(y_test, predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cb6f9528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'in <string>' requires string as left operand, not csr_matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Step 6: Fit the pipeline on training data\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Step 7: Make predictions on test data\u001b[39;00m\n\u001b[0;32m     77\u001b[0m predict \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 401\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    357\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\pipeline.py:1192\u001b[0m, in \u001b[0;36mFeatureUnion.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit all transformers, transform the data and concatenate results.\u001b[39;00m\n\u001b[0;32m   1173\u001b[0m \n\u001b[0;32m   1174\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;124;03m        sum of `n_components` (output dimension) over transformers.\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1192\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results:\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n\u001b[0;32m   1195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\pipeline.py:1214\u001b[0m, in \u001b[0;36mFeatureUnion._parallel_func\u001b[1;34m(self, X, y, fit_params, func)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformer_weights()\n\u001b[0;32m   1212\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter())\n\u001b[1;32m-> 1214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFeatureUnion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\pipeline.py:437\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \n\u001b[0;32m    412\u001b[0m \u001b[38;5;124;03mFits all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;124;03m    Transformed samples.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    436\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 437\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m last_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    357\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1388\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1380\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1381\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1385\u001b[0m             )\n\u001b[0;32m   1386\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1391\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1275\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1274\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1275\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1276\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:108\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    106\u001b[0m     doc \u001b[38;5;241m=\u001b[39m decoder(doc)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 108\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[76], line 36\u001b[0m, in \u001b[0;36mpre_process\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpre_process\u001b[39m(text):\n\u001b[1;32m---> 36\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mchar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpunctuation\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     37\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(text)\n\u001b[0;32m     38\u001b[0m     text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[0-9]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n",
      "Cell \u001b[1;32mIn[76], line 36\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpre_process\u001b[39m(text):\n\u001b[1;32m---> 36\u001b[0m     text \u001b[38;5;241m=\u001b[39m [char \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m text \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mchar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpunctuation\u001b[49m]\n\u001b[0;32m     37\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(text)\n\u001b[0;32m     38\u001b[0m     text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[0-9]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'in <string>' requires string as left operand, not csr_matrix"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "# Step 1: Load the data\n",
    "df = pd.read_excel('Participants_Data_News_category/Data_Train.xlsx')\n",
    "\n",
    "# Step 2: Preprocessing functions\n",
    "nltk.download('wordnet')\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def pre_process(text):\n",
    "    text = [char for char in text if char not in string.punctuation]\n",
    "    text = ''.join(text)\n",
    "    text = re.sub('[0-9]', '', text)\n",
    "    no_stop = [word for word in text.split() if word not in stopwords.words('english')]\n",
    "    no_stop = ' '.join(no_stop)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_tokens = word_tokenize(no_stop)\n",
    "    fin_txt = ' '.join([lemmatizer.lemmatize(word) for word in word_tokens])\n",
    "    return fin_txt\n",
    "\n",
    "# Step 3: Custom Feature Transformer\n",
    "class CustomFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        word_length = X.apply(lambda x: len(x.split()))\n",
    "        text_length = X.apply(len)\n",
    "        return csr_matrix(np.column_stack((word_length, text_length)))\n",
    "\n",
    "# Step 4: Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('text_pipeline', Pipeline([\n",
    "            ('custom_features', CustomFeatureTransformer()),\n",
    "            ('preprocess', CountVectorizer(analyzer=pre_process)),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('classifier', xgb.XGBClassifier())\n",
    "])\n",
    "\n",
    "# Step 5: Split the data into train and test sets\n",
    "X = df['STORY']\n",
    "y = df['SECTION']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 6: Fit the pipeline on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Make predictions on test data\n",
    "predict = pipeline.predict(X_test)\n",
    "\n",
    "# Step 8: Evaluate the model's performance\n",
    "print(accuracy_score(y_test, predict))\n",
    "print(classification_report(y_test, predict))\n",
    "print(confusion_matrix(y_test, predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2ac7d44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8007863695937091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.80       491\n",
      "           1       0.79      0.84      0.81       846\n",
      "           2       0.86      0.85      0.86       598\n",
      "           3       0.69      0.65      0.67       354\n",
      "\n",
      "    accuracy                           0.80      2289\n",
      "   macro avg       0.79      0.78      0.79      2289\n",
      "weighted avg       0.80      0.80      0.80      2289\n",
      "\n",
      "[[381  59  25  26]\n",
      " [ 30 714  43  59]\n",
      " [ 19  54 509  16]\n",
      " [ 31  81  13 229]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Step 1: Load the data\n",
    "df = pd.read_excel('Participants_Data_News_category/Data_Train.xlsx')\n",
    "\n",
    "# Step 2: Preprocessing functions\n",
    "nltk.download('wordnet')\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def pre_process(text):\n",
    "    text = [char for char in text if char not in string.punctuation]\n",
    "    text = ''.join(text)\n",
    "    text = re.sub('[0-9]', '', text)\n",
    "    no_stop = [word for word in text.split() if word not in stopwords.words('english')]\n",
    "    no_stop = ' '.join(no_stop)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_tokens = word_tokenize(no_stop)\n",
    "    fin_txt = ' '.join([lemmatizer.lemmatize(word) for word in word_tokens])\n",
    "    return fin_txt\n",
    "\n",
    "# Step 3: Custom Feature Transformer\n",
    "class CustomFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        word_length = X.apply(lambda x: len(x.split())).to_frame()\n",
    "        text_length = X.apply(len).to_frame()\n",
    "        return np.hstack((word_length, text_length))\n",
    "\n",
    "# Step 4: Create pipeline\n",
    "text_pipeline = Pipeline([\n",
    "    ('preprocess', CountVectorizer(analyzer=pre_process)),\n",
    "    ('tfidf', TfidfTransformer())\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', ColumnTransformer([\n",
    "        ('text_features', text_pipeline, 'STORY'),\n",
    "        ('custom_features', CustomFeatureTransformer(), 'STORY')\n",
    "    ])),\n",
    "    ('classifier', xgb.XGBClassifier())\n",
    "])\n",
    "\n",
    "# Step 5: Split the data into train and test sets\n",
    "X = df[['STORY']]\n",
    "y = df['SECTION']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 6: Fit the pipeline on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Make predictions on test data\n",
    "predict = pipeline.predict(X_test)\n",
    "\n",
    "# Step 8: Evaluate the model's performance\n",
    "print(accuracy_score(y_test, predict))\n",
    "print(classification_report(y_test, predict))\n",
    "print(confusion_matrix(y_test, predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4869c3",
   "metadata": {},
   "source": [
    "When i apply the pipeline the model performance is decreassing \n",
    "\n",
    "there is so many proplem that why this is happening such as data leak and feature work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2094c33b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
